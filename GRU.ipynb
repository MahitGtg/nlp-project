{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeNVhtG0clTY"
   },
   "source": [
    "# 2025 CITS4012 Project 2\n",
    "\n",
    "## 1. Preprocessing\n",
    "\n",
    "### 1.1. Import Libraries\n",
    "Libraries are imported for the entire project.\n",
    "\n",
    "*Note: Just add to this list as needed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZHKYoflWbaOB",
    "outputId": "04a1c479-c26a-40d2-f7b8-01a684a90319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\justmitch\\documents\\cits4012\\.venv\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\justmitch\\documents\\cits4012\\.venv\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\justmitch\\documents\\cits4012\\.venv\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\justmitch\\documents\\cits4012\\.venv\\lib\\site-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\justmitch\\documents\\cits4012\\.venv\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "# from pydrive2.auth import GoogleAuth\n",
    "# from pydrive2.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "import itertools\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lm0j1IPpdoMH"
   },
   "source": [
    "### 1.2. Retrieve Data\n",
    "First, we need to retrieve the train/val/test datafiles from the Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sf7SEIIWbbFB"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBuq3Zf_bdai"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m val_fileid = \u001b[33m\"\u001b[39m\u001b[33m15FEgtzzTVDMQcNVMgwIwqoAJeF9vmtrX\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m test_fileid = \u001b[33m\"\u001b[39m\u001b[33m179nwaOvdkZ3ogsBaTSJvpZEIjq20uiG-\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m train_file = \u001b[43mdrive\u001b[49m.CreateFile({\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m: train_fileid})\n\u001b[32m      6\u001b[39m val_file = drive.CreateFile({\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m: val_fileid})\n\u001b[32m      7\u001b[39m test_file = drive.CreateFile({\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m: test_fileid})\n",
      "\u001b[31mNameError\u001b[39m: name 'drive' is not defined"
     ]
    }
   ],
   "source": [
    "train_fileid = \"1YEOo5vd8DXXUCf1FXCR1D3PxWR9XxQKv\"\n",
    "val_fileid = \"15FEgtzzTVDMQcNVMgwIwqoAJeF9vmtrX\"\n",
    "test_fileid = \"179nwaOvdkZ3ogsBaTSJvpZEIjq20uiG-\"\n",
    "\n",
    "train_file = drive.CreateFile({'id': train_fileid})\n",
    "val_file = drive.CreateFile({'id': val_fileid})\n",
    "test_file = drive.CreateFile({'id': test_fileid})\n",
    "\n",
    "train_file.GetContentFile('train.json')\n",
    "val_file.GetContentFile('val.json')\n",
    "test_file.GetContentFile('test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1jcNQxncz-Y"
   },
   "source": [
    "### 1.3. Read in the Data\n",
    "We now read in each dataset, splitting the input data and target data. The data shapes and a sample of the training data are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "iFkL1hHIcYQD",
    "outputId": "6a1bcc36-de64-4f7d-fad9-82bd728e326a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (23088, 2)\n",
      "Val shape: (1304, 2)\n",
      "Test shape: (2126, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "premise",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hypothesis",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "3ee243bf-3b25-4b9f-9af8-b77621902860",
       "rows": [
        [
         "0",
         "Pluto rotates once on its axis every 6.39 Earth days;",
         "Earth rotates on its axis once times in one day.",
         "neutral"
        ],
        [
         "1",
         "---Glenn ========================================================= Once per day, the earth rotates about its axis.",
         "Earth rotates on its axis once times in one day.",
         "entails"
        ],
        [
         "2",
         "geysers - periodic gush of hot water at the surface of the Earth.",
         "The surface of the sun is much hotter than almost anything on earth.",
         "neutral"
        ],
        [
         "3",
         "Facts: Liquid water droplets can be changed into invisible water vapor through a process called evaporation .",
         "Evaporation is responsible for changing liquid water into water vapor.",
         "entails"
        ],
        [
         "4",
         "By comparison, the earth rotates on its axis once per day and revolves around the sun once per year.",
         "Earth rotates on its axis once times in one day.",
         "entails"
        ],
        [
         "5",
         "Pluto is about 39 times more distant from the Sun than is the Earth, and it takes about 250 Earth years for Pluto to make one complete revolution around the Sun.",
         "Earth makes a complete revolution around the sun about once every year.",
         "neutral"
        ],
        [
         "6",
         "It takes Pluto 247.7 Earth years to make one revolution around the Sun.",
         "Earth makes a complete revolution around the sun about once every year.",
         "neutral"
        ],
        [
         "7",
         "Multicellular organisms that have a eukaryotic cell type, mitochondria and a complex nervous system.",
         "Single-celled organisms and multicellular organisms have this in common: both have a way to get rid of waste materials.",
         "neutral"
        ],
        [
         "8",
         "Distribution Water on earth is located primarily in the oceans (97.2%), polar caps (2.14%), ground water(0.61%), and surface water(0.009%).",
         "Most of earth's water is located in oceans",
         "entails"
        ],
        [
         "9",
         "migratory birds which fly from South America to winter in Arctic Circle, where they",
         "Many species of birds in new england fly south for the winter months to find an environment with more food.",
         "neutral"
        ],
        [
         "10",
         "Younger children learn about different forms of energy, including heat, light and sound, though concrete activities.",
         "Heat, light, and sound are all different forms of energy.",
         "entails"
        ],
        [
         "11",
         "When enough condensation forms, it will rain and water the plants.",
         "Dew forming on plants during a cold night is an example of water condensing.",
         "neutral"
        ],
        [
         "12",
         "The photosynthesis of the past is what had stored the Sun's energy that ultimately produced coal;",
         "Coal is nonrenewable, and the sun is renewable is how coal and the sun compare as sources of energy.",
         "neutral"
        ],
        [
         "13",
         "Around the liquid stor- age and liquid recovery systems, rain water runoff would be controlled by collection into a sump system.",
         "Rain is an example of liquid water.",
         "neutral"
        ],
        [
         "14",
         "In this last example, it isn't even loudness or sound at all that needs to be made.",
         "The sound in a loud classroom is an example of a form of energy.",
         "neutral"
        ],
        [
         "15",
         "When these winds are strong, they deflect moister air moving up from the Gulf coast and cold air masses moving down from the Arctic;",
         "The best explanation for how air masses move across the united states is that the prevailing westerlies move air masses from west to east across the united states but may be deflected by the jet stream.",
         "neutral"
        ],
        [
         "16",
         "Evaporation : The process that changes water (liquid) into water vapor (gas).",
         "Evaporation is responsible for changing liquid water into water vapor.",
         "entails"
        ],
        [
         "17",
         "A long-day plant (a plant that flowers in the early summer in response to increasing day length) will be used to isolate the appropriate promoters.",
         "A(n) increase in length happens to metal railroad tracks during the heat of a summer day.",
         "neutral"
        ],
        [
         "18",
         "Why do we find few or no human fossils in most sedimentary rock?",
         "Most fossils are found in sedimentary rocks because organisms can be preserved in sedimentary rock.",
         "neutral"
        ],
        [
         "19",
         "Even if you don't live near a stream or river (though most people do), there are many little things you can do to help prevent too much water and soil run-off from contaminating streams and rivers where anadromous fishes live: Keep your lawn vegetated.",
         "People can help keep a forest a good place for birds to live by preventing too many trees from being cut down.",
         "neutral"
        ],
        [
         "20",
         "MINERALS A mineral is any naturally-occurring, homogeneous solid that has a definite chemical composition and a distinctive internal crystal structure.",
         "A mineral is described as a solid natural material with a crystal structure.",
         "entails"
        ],
        [
         "21",
         "Selfish Cells Threaten Multicellular Life, Trends in Ecology and Evolution Excerpt: How far have conflicts at the cell and organism level influenced the evolution of multicellularity?",
         "Single-celled organisms and multicellular organisms have this in common: both have a way to get rid of waste materials.",
         "neutral"
        ],
        [
         "22",
         "Frogs replace them with lungs in the transition from tadpoles to adults.",
         "A frog develops (a/an) lungs as it changes from a tadpole to an adult frog.",
         "entails"
        ],
        [
         "23",
         "3) The earth is far enough from the sun so that its surface temperature isn't unbearably hot .",
         "The surface of the sun is much hotter than almost anything on earth.",
         "neutral"
        ],
        [
         "24",
         "Solar system: the Sun and all bodies orbiting around it.",
         "The largest body in our solar system is the sun.",
         "neutral"
        ],
        [
         "25",
         "The sun and stars appeared exactly as they do to us upon earth.",
         "From earth, the sun appears brighter than any other star because the sun is the closest star",
         "neutral"
        ],
        [
         "26",
         "Indeed, these and most fungi are multicellular organisms made up of cells have cell walls, a typical plant characteristic.",
         "Single-celled organisms and multicellular organisms have this in common: both have a way to get rid of waste materials.",
         "neutral"
        ],
        [
         "27",
         "For example, active health is offered in every grade to teach students to monitor their own healthy habits such as nutrition, substance abuse and smoking.",
         "Exercising every day is an example of a good health habit.",
         "neutral"
        ],
        [
         "28",
         "Identify her master traits and provide an example from the reading for each trait.",
         "Being able to read is an example of a learned trait.",
         "neutral"
        ],
        [
         "29",
         "On Titan, rain and clouds are most likely made up of liquid methane, not water.",
         "Rain is an example of liquid water.",
         "neutral"
        ],
        [
         "30",
         "CSX operates a north-south length of railroad track that connects Chrisman and Paris.",
         "A(n) increase in length happens to metal railroad tracks during the heat of a summer day.",
         "neutral"
        ],
        [
         "31",
         "Slugs, believe it or not have a very important purpose. They are decomposers, which means they eats wastes and organic materials of other organisms. They help get rid of the t…rash that animals leave behind.",
         "Single-celled organisms and multicellular organisms have this in common: both have a way to get rid of waste materials.",
         "neutral"
        ],
        [
         "32",
         "I 4.4.3d Different forms of energy include heat, light, electrical, mechanical, sound, nuclear, and chemical.",
         "Heat, light, and sound are all different forms of energy.",
         "entails"
        ],
        [
         "33",
         "Your eyes of blue and hair that's straight, Comes through heredity, inheriting a human trait.",
         "A human offspring inherit blue eyes.",
         "entails"
        ],
        [
         "34",
         "Energy, heat and/or sound are forms of matter.",
         "Heat, light, and sound are all different forms of energy.",
         "neutral"
        ],
        [
         "35",
         "What good are cactus spines?",
         "The spines of a cactus help it survive because spines protect the cactus from animals.",
         "neutral"
        ],
        [
         "36",
         "The energy in the coal came from the sun and was stored in the plants.",
         "Coal is nonrenewable, and the sun is renewable is how coal and the sun compare as sources of energy.",
         "neutral"
        ],
        [
         "37",
         "Of course, the Sun is the closest star to Earth.",
         "From earth, the sun appears brighter than any other star because the sun is the closest star",
         "entails"
        ],
        [
         "38",
         "Pumpkin Fruit RollUps Chop pumpkin and cook in saucepan until soft.",
         "A pumpkin is a fruit.",
         "neutral"
        ],
        [
         "39",
         "Wait for a series of blue blocks to appear and fill the slot.",
         "A blue block appears blue in the sunlight if only blue light is reflected by the block.",
         "neutral"
        ],
        [
         "40",
         "Be able to give examples of the marketing applications of these types of learning.",
         "Being able to read is an example of a learned trait.",
         "neutral"
        ],
        [
         "41",
         "as, to inject cold water into a condenser;",
         "Dew forming on plants during a cold night is an example of water condensing.",
         "neutral"
        ],
        [
         "42",
         "The cholla, with its long spines, provides a well protected home for the cactus wren and its young.",
         "The spines of a cactus help it survive because spines protect the cactus from animals.",
         "neutral"
        ],
        [
         "43",
         "turbulent flow) air flow rate The mass/volume of air moved per unit of time through a space opening or duct.",
         "The best explanation for how air masses move across the united states is that the prevailing westerlies move air masses from west to east across the united states but may be deflected by the jet stream.",
         "neutral"
        ],
        [
         "44",
         "As a House of Animals There are many trees living in woods, and their flowers, nuts and fruits support the life of small animals such as a squirrel.",
         "A squirrel storing nuts is preparing for a seasonal change in the environment.",
         "neutral"
        ],
        [
         "45",
         "We may, for example, respond to a loud noise by saying \"That sounded like a gunshot.\"",
         "The sound in a loud classroom is an example of a form of energy.",
         "neutral"
        ],
        [
         "46",
         "Now the carbon atom we are following is sent out inlo the air as a part of a carbon dioxide molecule again.",
         "Air is made of atoms.",
         "neutral"
        ],
        [
         "47",
         "In some programs, genetic counselors use DNA fingerprint information to help prospective parents understand the risk of having an affected child.",
         "Children resemble their parents because they have similar dna.",
         "neutral"
        ],
        [
         "48",
         "Genes determine all inherited traits including those that give the individual specific characteristics (blue eyes rather than brown eyes) as well as common characteristics (two eyes, two arms, etc.).",
         "A human offspring inherit blue eyes.",
         "entails"
        ],
        [
         "49",
         "An organism eats other living things to survive;",
         "A moose eats a plant is an example of a living thing that depends on another living thing to survive.",
         "entails"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 23088
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pluto rotates once on its axis every 6.39 Eart...</td>\n",
       "      <td>Earth rotates on its axis once times in one day.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---Glenn =====================================...</td>\n",
       "      <td>Earth rotates on its axis once times in one day.</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>geysers - periodic gush of hot water at the su...</td>\n",
       "      <td>The surface of the sun is much hotter than alm...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facts: Liquid water droplets can be changed in...</td>\n",
       "      <td>Evaporation is responsible for changing liquid...</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>By comparison, the earth rotates on its axis o...</td>\n",
       "      <td>Earth rotates on its axis once times in one day.</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23083</th>\n",
       "      <td>which is not only the motion of our bodies, bu...</td>\n",
       "      <td>Work is done only if a force is exerted in the...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23084</th>\n",
       "      <td>The Red Star, that celestial curse whose eccen...</td>\n",
       "      <td>Red-shift refers to a shift toward red in the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23085</th>\n",
       "      <td>The lines in the spectrum of a luminous body s...</td>\n",
       "      <td>Red-shift refers to a shift toward red in the ...</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23086</th>\n",
       "      <td>The radial velocity of a star away from or tow...</td>\n",
       "      <td>Red-shift refers to a shift toward red in the ...</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23087</th>\n",
       "      <td>This expansion causes the light from distant s...</td>\n",
       "      <td>Red-shift refers to a shift toward red in the ...</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23088 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 premise  \\\n",
       "0      Pluto rotates once on its axis every 6.39 Eart...   \n",
       "1      ---Glenn =====================================...   \n",
       "2      geysers - periodic gush of hot water at the su...   \n",
       "3      Facts: Liquid water droplets can be changed in...   \n",
       "4      By comparison, the earth rotates on its axis o...   \n",
       "...                                                  ...   \n",
       "23083  which is not only the motion of our bodies, bu...   \n",
       "23084  The Red Star, that celestial curse whose eccen...   \n",
       "23085  The lines in the spectrum of a luminous body s...   \n",
       "23086  The radial velocity of a star away from or tow...   \n",
       "23087  This expansion causes the light from distant s...   \n",
       "\n",
       "                                              hypothesis    label  \n",
       "0       Earth rotates on its axis once times in one day.  neutral  \n",
       "1       Earth rotates on its axis once times in one day.  entails  \n",
       "2      The surface of the sun is much hotter than alm...  neutral  \n",
       "3      Evaporation is responsible for changing liquid...  entails  \n",
       "4       Earth rotates on its axis once times in one day.  entails  \n",
       "...                                                  ...      ...  \n",
       "23083  Work is done only if a force is exerted in the...  neutral  \n",
       "23084  Red-shift refers to a shift toward red in the ...  neutral  \n",
       "23085  Red-shift refers to a shift toward red in the ...  entails  \n",
       "23086  Red-shift refers to a shift toward red in the ...  entails  \n",
       "23087  Red-shift refers to a shift toward red in the ...  entails  \n",
       "\n",
       "[23088 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_json('train.json')\n",
    "X_train = train[['premise', 'hypothesis']]\n",
    "y_train = train['label']\n",
    "\n",
    "val = pd.read_json('val.json')\n",
    "X_val = val[['premise', 'hypothesis']]\n",
    "y_val = val['label']\n",
    "\n",
    "test = pd.read_json('test.json')\n",
    "X_test = test[['premise', 'hypothesis']]\n",
    "y_test = test['label']\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Val shape: {X_val.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")\n",
    "display(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VtFvjtVfaqe"
   },
   "source": [
    "### 1.4. Data preprocessing\n",
    "As seen above, the data contains characters that requires cleaning before passing it to the model.\n",
    "\n",
    "The preprocessing pipeline is as follows:\n",
    "- Sentences are tokenised using SpaCy.\n",
    "- A vocabulary list is constructed, including a padding and out-of-vocabulary tag.\n",
    "- A GloVe Embedding model is loaded, pretrained on twitter.\n",
    "- Tokenised sentences are converted to an indexed list of words, padded to the maximum size of the premise and hypothesis, respectively.\n",
    "\n",
    "The labels are also converted to 0 or 1 (0 = neutral, 1 = entails).\n",
    "\n",
    "#### 1.4.1. SpaCy Tokenisation\n",
    "We tokenise the premises and hypotheses for the datasets - removing all non alphanumeric characters and converting words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "ydgaNHsXfLk6",
    "outputId": "879f825f-b721-4817-cfb2-b38a1f571920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "Tokenising                                                  premise  \\\n",
      "0      Pluto rotates once on its axis every 6.39 Eart...   \n",
      "1      ---Glenn =====================================...   \n",
      "2      geysers - periodic gush of hot water at the su...   \n",
      "3      Facts: Liquid water droplets can be changed in...   \n",
      "4      By comparison, the earth rotates on its axis o...   \n",
      "...                                                  ...   \n",
      "23083  which is not only the motion of our bodies, bu...   \n",
      "23084  The Red Star, that celestial curse whose eccen...   \n",
      "23085  The lines in the spectrum of a luminous body s...   \n",
      "23086  The radial velocity of a star away from or tow...   \n",
      "23087  This expansion causes the light from distant s...   \n",
      "\n",
      "                                              hypothesis  \n",
      "0       Earth rotates on its axis once times in one day.  \n",
      "1       Earth rotates on its axis once times in one day.  \n",
      "2      The surface of the sun is much hotter than alm...  \n",
      "3      Evaporation is responsible for changing liquid...  \n",
      "4       Earth rotates on its axis once times in one day.  \n",
      "...                                                  ...  \n",
      "23083  Work is done only if a force is exerted in the...  \n",
      "23084  Red-shift refers to a shift toward red in the ...  \n",
      "23085  Red-shift refers to a shift toward red in the ...  \n",
      "23086  Red-shift refers to a shift toward red in the ...  \n",
      "23087  Red-shift refers to a shift toward red in the ...  \n",
      "\n",
      "[23088 rows x 2 columns]...\n",
      "Tokenising                                                 premise  \\\n",
      "0     An introduction to atoms and elements, compoun...   \n",
      "1     Wavelength The distance between two consecutiv...   \n",
      "2         humans normally have 23 pairs of chromosomes.   \n",
      "3     Photosynthesis, fermentation, glycolysis, aero...   \n",
      "4     The pungent smell of the yellow, toffee colore...   \n",
      "...                                                 ...   \n",
      "1299  The Web has several good sites giving details ...   \n",
      "1300  Since the amount of time we (usually) spend pr...   \n",
      "1301  Tides Lunar Eclipses Activities, Web Links LUN...   \n",
      "1302  Lunar Eclipses A lunar eclipse occurs when the...   \n",
      "1303  A lunar eclipse occurs when the Moon passes th...   \n",
      "\n",
      "                                             hypothesis  \n",
      "0     Replace another in a molecule happens to atoms...  \n",
      "1     Wavelength is the distance between two corresp...  \n",
      "2     Humans typically have 23 pairs pairs of chromo...  \n",
      "3     Glycolysis is a series of reactions that is co...  \n",
      "4     If a substance does not release molecules into...  \n",
      "...                                                 ...  \n",
      "1299  Only the sun in our solar system give off thei...  \n",
      "1300  This process usually takes the longest amount ...  \n",
      "1301  When earth’s shadow falls on the moon, the sha...  \n",
      "1302  When earth’s shadow falls on the moon, the sha...  \n",
      "1303  When earth’s shadow falls on the moon, the sha...  \n",
      "\n",
      "[1304 rows x 2 columns]...\n",
      "Tokenising                                                 premise  \\\n",
      "0     Based on the list provided of the uses of subs...   \n",
      "1     If one or two            base pairs are change...   \n",
      "2     At high temperatures, the solid dye converts i...   \n",
      "3                   Chapter 11 Gas and Kinetic Theory .   \n",
      "4     Both the continental crust and the oceanic cru...   \n",
      "...                                                 ...   \n",
      "2121  In addition, the small pieces of prairie mean ...   \n",
      "2122  D structures will help scientists determine be...   \n",
      "2123  Of particular relevance is the role of terrest...   \n",
      "2124  A new public gazebo at the water's edge is one...   \n",
      "2125  Inorganic, Bioinorganic, and Organometallic Ch...   \n",
      "\n",
      "                                             hypothesis  \n",
      "0     If a substance has a ph value greater than 7,t...  \n",
      "1     Invertebrates (and higher animals) can also be...  \n",
      "2     Gases and liquids become solids at low tempera...  \n",
      "3     The behavior of ideal gases is explained by ki...  \n",
      "4     Gabbro is a dark dense rock that can be found ...  \n",
      "...                                                 ...  \n",
      "2121  A fewer predators is most likely to cause the ...  \n",
      "2122  Studies of earthquake waves have helped scient...  \n",
      "2123  A primary role of decomposers in an ecosystem ...  \n",
      "2124                    One example of matter is water.  \n",
      "2125  Elements on the periodic table of the elements...  \n",
      "\n",
      "[2126 rows x 2 columns]...\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "premise",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "hypothesis",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "21d36dfb-92b7-4e1b-b110-b464e8cab9d0",
       "rows": [
        [
         "0",
         "['pluto', 'rotates', 'once', 'on', 'its', 'axis', 'every', 'earth', 'days']",
         "['earth', 'rotates', 'on', 'its', 'axis', 'once', 'times', 'in', 'one', 'day']"
        ],
        [
         "1",
         "['once', 'per', 'day', 'the', 'earth', 'rotates', 'about', 'its', 'axis']",
         "['earth', 'rotates', 'on', 'its', 'axis', 'once', 'times', 'in', 'one', 'day']"
        ],
        [
         "2",
         "['geysers', 'periodic', 'gush', 'of', 'hot', 'water', 'at', 'the', 'surface', 'of', 'the', 'earth']",
         "['the', 'surface', 'of', 'the', 'sun', 'is', 'much', 'hotter', 'than', 'almost', 'anything', 'on', 'earth']"
        ],
        [
         "3",
         "['facts', 'liquid', 'water', 'droplets', 'can', 'be', 'changed', 'into', 'invisible', 'water', 'vapor', 'through', 'a', 'process', 'called', 'evaporation']",
         "['evaporation', 'is', 'responsible', 'for', 'changing', 'liquid', 'water', 'into', 'water', 'vapor']"
        ],
        [
         "4",
         "['by', 'comparison', 'the', 'earth', 'rotates', 'on', 'its', 'axis', 'once', 'per', 'day', 'and', 'revolves', 'around', 'the', 'sun', 'once', 'per', 'year']",
         "['earth', 'rotates', 'on', 'its', 'axis', 'once', 'times', 'in', 'one', 'day']"
        ],
        [
         "5",
         "['pluto', 'is', 'about', '39', 'times', 'more', 'distant', 'from', 'the', 'sun', 'than', 'is', 'the', 'earth', 'and', 'it', 'takes', 'about', '250', 'earth', 'years', 'for', 'pluto', 'to', 'make', 'one', 'complete', 'revolution', 'around', 'the', 'sun']",
         "['earth', 'makes', 'a', 'complete', 'revolution', 'around', 'the', 'sun', 'about', 'once', 'every', 'year']"
        ],
        [
         "6",
         "['it', 'takes', 'pluto', 'earth', 'years', 'to', 'make', 'one', 'revolution', 'around', 'the', 'sun']",
         "['earth', 'makes', 'a', 'complete', 'revolution', 'around', 'the', 'sun', 'about', 'once', 'every', 'year']"
        ],
        [
         "7",
         "['multicellular', 'organisms', 'that', 'have', 'a', 'eukaryotic', 'cell', 'type', 'mitochondria', 'and', 'a', 'complex', 'nervous', 'system']",
         "['single', 'celled', 'organisms', 'and', 'multicellular', 'organisms', 'have', 'this', 'in', 'common', 'both', 'have', 'a', 'way', 'to', 'get', 'rid', 'of', 'waste', 'materials']"
        ],
        [
         "8",
         "['distribution', 'water', 'on', 'earth', 'is', 'located', 'primarily', 'in', 'the', 'oceans', 'polar', 'caps', 'ground', 'and', 'surface']",
         "['most', 'of', 'earth', 'water', 'is', 'located', 'in', 'oceans']"
        ],
        [
         "9",
         "['migratory', 'birds', 'which', 'fly', 'from', 'south', 'america', 'to', 'winter', 'in', 'arctic', 'circle', 'where', 'they']",
         "['many', 'species', 'of', 'birds', 'in', 'new', 'england', 'fly', 'south', 'for', 'the', 'winter', 'months', 'to', 'find', 'an', 'environment', 'with', 'more', 'food']"
        ],
        [
         "10",
         "['younger', 'children', 'learn', 'about', 'different', 'forms', 'of', 'energy', 'including', 'heat', 'light', 'and', 'sound', 'though', 'concrete', 'activities']",
         "['heat', 'light', 'and', 'sound', 'are', 'all', 'different', 'forms', 'of', 'energy']"
        ],
        [
         "11",
         "['when', 'enough', 'condensation', 'forms', 'it', 'will', 'rain', 'and', 'water', 'the', 'plants']",
         "['dew', 'forming', 'on', 'plants', 'during', 'a', 'cold', 'night', 'is', 'an', 'example', 'of', 'water', 'condensing']"
        ],
        [
         "12",
         "['the', 'photosynthesis', 'of', 'the', 'past', 'is', 'what', 'had', 'stored', 'the', 'sun', 'energy', 'that', 'ultimately', 'produced', 'coal']",
         "['coal', 'is', 'nonrenewable', 'and', 'the', 'sun', 'is', 'renewable', 'is', 'how', 'coal', 'and', 'the', 'sun', 'compare', 'as', 'sources', 'of', 'energy']"
        ],
        [
         "13",
         "['around', 'the', 'liquid', 'age', 'and', 'liquid', 'recovery', 'systems', 'rain', 'water', 'runoff', 'would', 'be', 'controlled', 'by', 'collection', 'into', 'a', 'sump', 'system']",
         "['rain', 'is', 'an', 'example', 'of', 'liquid', 'water']"
        ],
        [
         "14",
         "['in', 'this', 'last', 'example', 'it', 'is', 'even', 'loudness', 'or', 'sound', 'at', 'all', 'that', 'needs', 'to', 'be', 'made']",
         "['the', 'sound', 'in', 'a', 'loud', 'classroom', 'is', 'an', 'example', 'of', 'a', 'form', 'of', 'energy']"
        ],
        [
         "15",
         "['when', 'these', 'winds', 'are', 'strong', 'they', 'deflect', 'moister', 'air', 'moving', 'up', 'from', 'the', 'gulf', 'coast', 'and', 'cold', 'air', 'masses', 'moving', 'down', 'from', 'the', 'arctic']",
         "['the', 'best', 'explanation', 'for', 'how', 'air', 'masses', 'move', 'across', 'the', 'united', 'states', 'is', 'that', 'the', 'prevailing', 'westerlies', 'move', 'air', 'masses', 'from', 'west', 'to', 'east', 'across', 'the', 'united', 'states', 'but', 'may', 'be', 'deflected', 'by', 'the', 'jet', 'stream']"
        ],
        [
         "16",
         "['evaporation', 'the', 'process', 'that', 'changes', 'water', 'liquid', 'into', 'water', 'vapor', 'gas']",
         "['evaporation', 'is', 'responsible', 'for', 'changing', 'liquid', 'water', 'into', 'water', 'vapor']"
        ],
        [
         "17",
         "['a', 'long', 'day', 'plant', 'a', 'plant', 'that', 'flowers', 'in', 'the', 'early', 'summer', 'in', 'response', 'to', 'increasing', 'day', 'length', 'will', 'be', 'used', 'to', 'isolate', 'the', 'appropriate', 'promoters']",
         "['increase', 'in', 'length', 'happens', 'to', 'metal', 'railroad', 'tracks', 'during', 'the', 'heat', 'of', 'a', 'summer', 'day']"
        ],
        [
         "18",
         "['why', 'do', 'we', 'find', 'few', 'or', 'no', 'human', 'fossils', 'in', 'most', 'sedimentary', 'rock']",
         "['most', 'fossils', 'are', 'found', 'in', 'sedimentary', 'rocks', 'because', 'organisms', 'can', 'be', 'preserved', 'in', 'sedimentary', 'rock']"
        ],
        [
         "19",
         "['even', 'if', 'you', 'do', 'live', 'near', 'a', 'stream', 'or', 'river', 'though', 'most', 'people', 'do', 'there', 'are', 'many', 'little', 'things', 'you', 'can', 'do', 'to', 'help', 'prevent', 'too', 'much', 'water', 'and', 'soil', 'run', 'off', 'from', 'contaminating', 'streams', 'and', 'rivers', 'where', 'anadromous', 'fishes', 'live', 'keep', 'your', 'lawn', 'vegetated']",
         "['people', 'can', 'help', 'keep', 'a', 'forest', 'a', 'good', 'place', 'for', 'birds', 'to', 'live', 'by', 'preventing', 'too', 'many', 'trees', 'from', 'being', 'cut', 'down']"
        ],
        [
         "20",
         "['minerals', 'a', 'mineral', 'is', 'any', 'naturally', 'occurring', 'homogeneous', 'solid', 'that', 'has', 'a', 'definite', 'chemical', 'composition', 'and', 'a', 'distinctive', 'internal', 'crystal', 'structure']",
         "['a', 'mineral', 'is', 'described', 'as', 'a', 'solid', 'natural', 'material', 'with', 'a', 'crystal', 'structure']"
        ],
        [
         "21",
         "['selfish', 'cells', 'threaten', 'multicellular', 'life', 'trends', 'in', 'ecology', 'and', 'evolution', 'excerpt', 'how', 'far', 'have', 'conflicts', 'at', 'the', 'cell', 'and', 'organism', 'level', 'influenced', 'the', 'evolution', 'of', 'multicellularity']",
         "['single', 'celled', 'organisms', 'and', 'multicellular', 'organisms', 'have', 'this', 'in', 'common', 'both', 'have', 'a', 'way', 'to', 'get', 'rid', 'of', 'waste', 'materials']"
        ],
        [
         "22",
         "['frogs', 'replace', 'them', 'with', 'lungs', 'in', 'the', 'transition', 'from', 'tadpoles', 'to', 'adults']",
         "['a', 'frog', 'develops', 'a', 'an', 'lungs', 'as', 'it', 'changes', 'from', 'a', 'tadpole', 'to', 'an', 'adult', 'frog']"
        ],
        [
         "23",
         "['3', 'the', 'earth', 'is', 'far', 'enough', 'from', 'the', 'sun', 'so', 'that', 'its', 'surface', 'temperature', 'is', 'unbearably', 'hot']",
         "['the', 'surface', 'of', 'the', 'sun', 'is', 'much', 'hotter', 'than', 'almost', 'anything', 'on', 'earth']"
        ],
        [
         "24",
         "['solar', 'system', 'the', 'sun', 'and', 'all', 'bodies', 'orbiting', 'around', 'it']",
         "['the', 'largest', 'body', 'in', 'our', 'solar', 'system', 'is', 'the', 'sun']"
        ],
        [
         "25",
         "['the', 'sun', 'and', 'stars', 'appeared', 'exactly', 'as', 'they', 'do', 'to', 'us', 'upon', 'earth']",
         "['from', 'earth', 'the', 'sun', 'appears', 'brighter', 'than', 'any', 'other', 'star', 'because', 'the', 'sun', 'is', 'the', 'closest', 'star']"
        ],
        [
         "26",
         "['indeed', 'these', 'and', 'most', 'fungi', 'are', 'multicellular', 'organisms', 'made', 'up', 'of', 'cells', 'have', 'cell', 'walls', 'a', 'typical', 'plant', 'characteristic']",
         "['single', 'celled', 'organisms', 'and', 'multicellular', 'organisms', 'have', 'this', 'in', 'common', 'both', 'have', 'a', 'way', 'to', 'get', 'rid', 'of', 'waste', 'materials']"
        ],
        [
         "27",
         "['for', 'example', 'active', 'health', 'is', 'offered', 'in', 'every', 'grade', 'to', 'teach', 'students', 'to', 'monitor', 'their', 'own', 'healthy', 'habits', 'such', 'as', 'nutrition', 'substance', 'abuse', 'and', 'smoking']",
         "['exercising', 'every', 'day', 'is', 'an', 'example', 'of', 'a', 'good', 'health', 'habit']"
        ],
        [
         "28",
         "['identify', 'her', 'master', 'traits', 'and', 'provide', 'an', 'example', 'from', 'the', 'reading', 'for', 'each', 'trait']",
         "['being', 'able', 'to', 'read', 'is', 'an', 'example', 'of', 'a', 'learned', 'trait']"
        ],
        [
         "29",
         "['on', 'titan', 'rain', 'and', 'clouds', 'are', 'most', 'likely', 'made', 'up', 'of', 'liquid', 'methane', 'not', 'water']",
         "['rain', 'is', 'an', 'example', 'of', 'liquid', 'water']"
        ],
        [
         "30",
         "['csx', 'operates', 'a', 'north', 'south', 'length', 'of', 'railroad', 'track', 'that', 'connects', 'chrisman', 'and', 'paris']",
         "['increase', 'in', 'length', 'happens', 'to', 'metal', 'railroad', 'tracks', 'during', 'the', 'heat', 'of', 'a', 'summer', 'day']"
        ],
        [
         "31",
         "['slugs', 'believe', 'it', 'or', 'not', 'have', 'a', 'very', 'important', 'purpose', 'they', 'are', 'decomposers', 'which', 'means', 'they', 'eats', 'wastes', 'and', 'organic', 'materials', 'of', 'other', 'organisms', 'they', 'help', 'get', 'rid', 'of', 'the', 't', 'rash', 'that', 'animals', 'leave', 'behind']",
         "['single', 'celled', 'organisms', 'and', 'multicellular', 'organisms', 'have', 'this', 'in', 'common', 'both', 'have', 'a', 'way', 'to', 'get', 'rid', 'of', 'waste', 'materials']"
        ],
        [
         "32",
         "['i', 'different', 'forms', 'of', 'energy', 'include', 'heat', 'light', 'electrical', 'mechanical', 'sound', 'nuclear', 'and', 'chemical']",
         "['heat', 'light', 'and', 'sound', 'are', 'all', 'different', 'forms', 'of', 'energy']"
        ],
        [
         "33",
         "['your', 'eyes', 'of', 'blue', 'and', 'hair', 'that', 'straight', 'comes', 'through', 'heredity', 'inheriting', 'a', 'human', 'trait']",
         "['a', 'human', 'offspring', 'inherit', 'blue', 'eyes']"
        ],
        [
         "34",
         "['energy', 'heat', 'sound', 'are', 'forms', 'of', 'matter']",
         "['heat', 'light', 'and', 'sound', 'are', 'all', 'different', 'forms', 'of', 'energy']"
        ],
        [
         "35",
         "['what', 'good', 'are', 'cactus', 'spines']",
         "['the', 'spines', 'of', 'a', 'cactus', 'help', 'it', 'survive', 'because', 'spines', 'protect', 'the', 'cactus', 'from', 'animals']"
        ],
        [
         "36",
         "['the', 'energy', 'in', 'the', 'coal', 'came', 'from', 'the', 'sun', 'and', 'was', 'stored', 'in', 'the', 'plants']",
         "['coal', 'is', 'nonrenewable', 'and', 'the', 'sun', 'is', 'renewable', 'is', 'how', 'coal', 'and', 'the', 'sun', 'compare', 'as', 'sources', 'of', 'energy']"
        ],
        [
         "37",
         "['of', 'course', 'the', 'sun', 'is', 'the', 'closest', 'star', 'to', 'earth']",
         "['from', 'earth', 'the', 'sun', 'appears', 'brighter', 'than', 'any', 'other', 'star', 'because', 'the', 'sun', 'is', 'the', 'closest', 'star']"
        ],
        [
         "38",
         "['pumpkin', 'fruit', 'rollups', 'chop', 'pumpkin', 'and', 'cook', 'in', 'saucepan', 'until', 'soft']",
         "['a', 'pumpkin', 'is', 'a', 'fruit']"
        ],
        [
         "39",
         "['wait', 'for', 'a', 'series', 'of', 'blue', 'blocks', 'to', 'appear', 'and', 'fill', 'the', 'slot']",
         "['a', 'blue', 'block', 'appears', 'blue', 'in', 'the', 'sunlight', 'if', 'only', 'blue', 'light', 'is', 'reflected', 'by', 'the', 'block']"
        ],
        [
         "40",
         "['be', 'able', 'to', 'give', 'examples', 'of', 'the', 'marketing', 'applications', 'of', 'these', 'types', 'of', 'learning']",
         "['being', 'able', 'to', 'read', 'is', 'an', 'example', 'of', 'a', 'learned', 'trait']"
        ],
        [
         "41",
         "['as', 'to', 'inject', 'cold', 'water', 'into', 'a', 'condenser']",
         "['dew', 'forming', 'on', 'plants', 'during', 'a', 'cold', 'night', 'is', 'an', 'example', 'of', 'water', 'condensing']"
        ],
        [
         "42",
         "['the', 'cholla', 'with', 'its', 'long', 'spines', 'provides', 'a', 'well', 'protected', 'home', 'for', 'the', 'cactus', 'wren', 'and', 'its', 'young']",
         "['the', 'spines', 'of', 'a', 'cactus', 'help', 'it', 'survive', 'because', 'spines', 'protect', 'the', 'cactus', 'from', 'animals']"
        ],
        [
         "43",
         "['turbulent', 'flow', 'air', 'flow', 'rate', 'the', 'mass', 'volume', 'of', 'air', 'moved', 'per', 'unit', 'of', 'time', 'through', 'a', 'space', 'opening', 'or', 'duct']",
         "['the', 'best', 'explanation', 'for', 'how', 'air', 'masses', 'move', 'across', 'the', 'united', 'states', 'is', 'that', 'the', 'prevailing', 'westerlies', 'move', 'air', 'masses', 'from', 'west', 'to', 'east', 'across', 'the', 'united', 'states', 'but', 'may', 'be', 'deflected', 'by', 'the', 'jet', 'stream']"
        ],
        [
         "44",
         "['as', 'a', 'house', 'of', 'animals', 'there', 'are', 'many', 'trees', 'living', 'in', 'woods', 'and', 'their', 'flowers', 'nuts', 'and', 'fruits', 'support', 'the', 'life', 'of', 'small', 'animals', 'such', 'as', 'a', 'squirrel']",
         "['a', 'squirrel', 'storing', 'nuts', 'is', 'preparing', 'for', 'a', 'seasonal', 'change', 'in', 'the', 'environment']"
        ],
        [
         "45",
         "['we', 'may', 'for', 'example', 'respond', 'to', 'a', 'loud', 'noise', 'by', 'saying', 'that', 'sounded', 'like', 'a', 'gunshot']",
         "['the', 'sound', 'in', 'a', 'loud', 'classroom', 'is', 'an', 'example', 'of', 'a', 'form', 'of', 'energy']"
        ],
        [
         "46",
         "['now', 'the', 'carbon', 'atom', 'we', 'are', 'following', 'is', 'sent', 'out', 'inlo', 'the', 'air', 'as', 'a', 'part', 'of', 'a', 'carbon', 'dioxide', 'molecule', 'again']",
         "['air', 'is', 'made', 'of', 'atoms']"
        ],
        [
         "47",
         "['in', 'some', 'programs', 'genetic', 'counselors', 'use', 'dna', 'fingerprint', 'information', 'to', 'help', 'prospective', 'parents', 'understand', 'the', 'risk', 'of', 'having', 'an', 'affected', 'child']",
         "['children', 'resemble', 'their', 'parents', 'because', 'they', 'have', 'similar', 'dna']"
        ],
        [
         "48",
         "['genes', 'determine', 'all', 'inherited', 'traits', 'including', 'those', 'that', 'give', 'the', 'individual', 'specific', 'characteristics', 'blue', 'eyes', 'rather', 'than', 'brown', 'eyes', 'as', 'well', 'as', 'common', 'characteristics', 'two', 'eyes', 'two', 'arms', 'etc']",
         "['a', 'human', 'offspring', 'inherit', 'blue', 'eyes']"
        ],
        [
         "49",
         "['an', 'organism', 'eats', 'other', 'living', 'things', 'to', 'survive']",
         "['a', 'moose', 'eats', 'a', 'plant', 'is', 'an', 'example', 'of', 'a', 'living', 'thing', 'that', 'depends', 'on', 'another', 'living', 'thing', 'to', 'survive']"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 23088
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pluto, rotates, once, on, its, axis, every, e...</td>\n",
       "      <td>[earth, rotates, on, its, axis, once, times, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[once, per, day, the, earth, rotates, about, i...</td>\n",
       "      <td>[earth, rotates, on, its, axis, once, times, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[geysers, periodic, gush, of, hot, water, at, ...</td>\n",
       "      <td>[the, surface, of, the, sun, is, much, hotter,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[facts, liquid, water, droplets, can, be, chan...</td>\n",
       "      <td>[evaporation, is, responsible, for, changing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[by, comparison, the, earth, rotates, on, its,...</td>\n",
       "      <td>[earth, rotates, on, its, axis, once, times, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23083</th>\n",
       "      <td>[which, is, not, only, the, motion, of, our, b...</td>\n",
       "      <td>[work, is, done, only, if, a, force, is, exert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23084</th>\n",
       "      <td>[the, red, star, that, celestial, curse, whose...</td>\n",
       "      <td>[red, shift, refers, to, a, shift, toward, red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23085</th>\n",
       "      <td>[the, lines, in, the, spectrum, of, a, luminou...</td>\n",
       "      <td>[red, shift, refers, to, a, shift, toward, red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23086</th>\n",
       "      <td>[the, radial, velocity, of, a, star, away, fro...</td>\n",
       "      <td>[red, shift, refers, to, a, shift, toward, red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23087</th>\n",
       "      <td>[this, expansion, causes, the, light, from, di...</td>\n",
       "      <td>[red, shift, refers, to, a, shift, toward, red...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23088 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 premise  \\\n",
       "0      [pluto, rotates, once, on, its, axis, every, e...   \n",
       "1      [once, per, day, the, earth, rotates, about, i...   \n",
       "2      [geysers, periodic, gush, of, hot, water, at, ...   \n",
       "3      [facts, liquid, water, droplets, can, be, chan...   \n",
       "4      [by, comparison, the, earth, rotates, on, its,...   \n",
       "...                                                  ...   \n",
       "23083  [which, is, not, only, the, motion, of, our, b...   \n",
       "23084  [the, red, star, that, celestial, curse, whose...   \n",
       "23085  [the, lines, in, the, spectrum, of, a, luminou...   \n",
       "23086  [the, radial, velocity, of, a, star, away, fro...   \n",
       "23087  [this, expansion, causes, the, light, from, di...   \n",
       "\n",
       "                                              hypothesis  \n",
       "0      [earth, rotates, on, its, axis, once, times, i...  \n",
       "1      [earth, rotates, on, its, axis, once, times, i...  \n",
       "2      [the, surface, of, the, sun, is, much, hotter,...  \n",
       "3      [evaporation, is, responsible, for, changing, ...  \n",
       "4      [earth, rotates, on, its, axis, once, times, i...  \n",
       "...                                                  ...  \n",
       "23083  [work, is, done, only, if, a, force, is, exert...  \n",
       "23084  [red, shift, refers, to, a, shift, toward, red...  \n",
       "23085  [red, shift, refers, to, a, shift, toward, red...  \n",
       "23086  [red, shift, refers, to, a, shift, toward, red...  \n",
       "23087  [red, shift, refers, to, a, shift, toward, red...  \n",
       "\n",
       "[23088 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.cli.download('en_core_web_sm')\n",
    "tokeniser = spacy.load('en_core_web_sm')\n",
    "for dataset in [X_train, X_val, X_test]:\n",
    "    print(f\"Tokenising {dataset}...\")\n",
    "    premise_list = dataset['premise'].tolist()\n",
    "    hypothesis_list = dataset['hypothesis'].tolist()\n",
    "\n",
    "    prem_tokens_list = list(tokeniser.pipe(premise_list, batch_size=64))\n",
    "    dataset.loc[:, \"premise\"] = [[token.text.lower() for token in tokens if re.match(r'^\\w+$', token.text)] for tokens in prem_tokens_list]\n",
    "\n",
    "    hyp_tokens_list = list(tokeniser.pipe(hypothesis_list, batch_size=64))\n",
    "    dataset.loc[:, \"hypothesis\"] = [[token.text.lower() for token in tokens if re.match(r'^\\w+$', token.text)] for tokens in hyp_tokens_list]\n",
    "\n",
    "display(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "td6uN2sPvAOM"
   },
   "source": [
    "#### 1.4.2. Vocabulary Construction\n",
    "We construct the vocabulary from the training set words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b52cccd",
    "outputId": "0fcd3a87-6873-4463-e5b8-3ebd2da1513d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 20127\n"
     ]
    }
   ],
   "source": [
    "vocab_set = set([])\n",
    "for tokens in X_train['premise']:\n",
    "    for token in tokens:\n",
    "        vocab_set.add(token)\n",
    "for tokens in X_train['hypothesis']:\n",
    "    for token in tokens:\n",
    "        vocab_set.add(token)\n",
    "\n",
    "# Convert the set to a list\n",
    "vocab = ['[PAD]', '[OOV]']\n",
    "vocab.extend(list(vocab_set))\n",
    "\n",
    "wordindexes = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "print(f\"Vocabulary size: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhqX6JwcvDEJ"
   },
   "source": [
    "#### 1.4.3 Embedding Table Creation\n",
    "We load the GloVe embeddings, and then for each word in the training set vocabulary, we add the embedding to our lookup table. If a word in the vocabulary does not exist in the GloVe embeddings, it is embedded as zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oe6VxxHYnEji",
    "outputId": "11c856b7-4010-44b5-efe6-fbd077015de0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20127, 100)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embeddings = api.load(\"glove-twitter-100\")\n",
    "\n",
    "emb_dim = glove_embeddings.vector_size\n",
    "emb_table = []\n",
    "for i, word in enumerate(vocab):\n",
    "    if word in glove_embeddings:\n",
    "        emb_table.append(glove_embeddings[word])\n",
    "    else:\n",
    "        emb_table.append(np.zeros(emb_dim))\n",
    "\n",
    "emb_table = np.array(emb_table)\n",
    "emb_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tMv8q2DvZtg"
   },
   "source": [
    "Later, we can now create an Embedding object that can be used to lookup the embeddings for any given word. This saves us from having to load the entire vocabulary embeddings at once during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqX7nBkMsl1W"
   },
   "source": [
    "### 1.5. Data visualisation\n",
    "We will visualise the data to observe any patterns that we should be aware of before preprocessing and training.\n",
    "\n",
    "First, lets observe the class balance for the train/val/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wPwxy8ss0nx",
    "outputId": "7e20e682-93d8-4945-8bd7-628668189561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set distribution:\n",
      "Neutral = 0.63\n",
      "Entails = 0.37\n",
      "Validation set distribution:\n",
      "Neutral = 0.5\n",
      "Entails = 0.5\n",
      "Testing set distribution:\n",
      "Neutral = 0.6\n",
      "Entails = 0.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Training set distribution:\\n\"\n",
    "    f\"Neutral = {round(y_train[y_train == 'neutral'].shape[0] / y_train.shape[0],2)}\\n\"\n",
    "    f\"Entails = {round(y_train[y_train == 'entails'].shape[0] / y_train.shape[0],2)}\\n\"\n",
    "    \"Validation set distribution:\\n\"\n",
    "    f\"Neutral = {round(y_val[y_val == 'neutral'].shape[0] / y_val.shape[0],2)}\\n\"\n",
    "    f\"Entails = {round(y_val[y_val == 'entails'].shape[0] / y_val.shape[0],2)}\\n\"\n",
    "    \"Testing set distribution:\\n\"\n",
    "    f\"Neutral = {round(y_test[y_test == 'neutral'].shape[0] / y_test.shape[0],2)}\\n\"\n",
    "    f\"Entails = {round(y_test[y_test == 'entails'].shape[0] / y_test.shape[0],2)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TUpK2UBtGXa"
   },
   "source": [
    "The training set is strongly skewed towards neutral samples - this will have an impact on training.\n",
    "\n",
    "Now, we will observe the distribution of the token lengths of the premises and hypotheses of the train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "6hgkN3eDs4RY",
    "outputId": "6d72f375-da0f-4298-b12e-d860280a32aa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_prem_lengths = [len(premise) for premise in X_train['premise']]\n",
    "train_hyp_lengths = [len(hypothesis) for hypothesis in X_train['hypothesis']]\n",
    "\n",
    "val_prem_lengths = [len(premise) for premise in X_val['premise']]\n",
    "val_hyp_lengths = [len(hypothesis) for hypothesis in X_val['hypothesis']]\n",
    "\n",
    "test_prem_lengths = [len(premise) for premise in X_test['premise']]\n",
    "test_hyp_lengths = [len(hypothesis) for hypothesis in X_test['hypothesis']]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Train set\n",
    "axs[0].hist(train_prem_lengths, bins=20, alpha=0.6, label='Premise')\n",
    "axs[0].hist(train_hyp_lengths, bins=20, alpha=0.6, label='Hypothesis')\n",
    "axs[0].set_title(\"Train Set Length Distribution\")\n",
    "axs[0].set_xlabel(\"Number of Tokens\")\n",
    "axs[0].set_ylabel(\"Frequency\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Validation set\n",
    "axs[1].hist(val_prem_lengths, bins=20, alpha=0.6, label='Premise')\n",
    "axs[1].hist(val_hyp_lengths, bins=20, alpha=0.6, label='Hypothesis')\n",
    "axs[1].set_title(\"Validation Set Length Distribution\")\n",
    "axs[1].set_xlabel(\"Number of Tokens\")\n",
    "axs[1].set_ylabel(\"Frequency\")\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].hist(test_prem_lengths, bins=20, alpha=0.6, label='Premise')\n",
    "axs[2].hist(test_hyp_lengths, bins=20, alpha=0.6, label='Hypothesis')\n",
    "axs[2].set_title(\"Test Set Length Distribution\")\n",
    "axs[2].set_xlabel(\"Number of Tokens\")\n",
    "axs[2].set_ylabel(\"Frequency\")\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sipBzYBu6qq"
   },
   "source": [
    "This indicates there are some outliers in the train set. To remove outliers (both small and large outliers), we removed the smallest and largest 2.5% of premises from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_prem, upper_prem = np.percentile(train_prem_lengths, [2.5, 97.5])\n",
    "keep_indices = [i for i, pl in enumerate(train_prem_lengths) if lower_prem <= pl <= upper_prem]\n",
    "X_train = X_train.iloc[keep_indices].reset_index(drop=True)\n",
    "y_train = y_train.iloc[keep_indices].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMwxCmJOvTVP"
   },
   "source": [
    "Removing these outliers from the training set, we get a nicer looking plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "96e4bb67",
    "outputId": "a304610f-6ad3-4bcb-ccca-c5b6f51bd745"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_prem_lengths = [len(premise) for premise in X_train['premise']]\n",
    "train_hyp_lengths = [len(hypothesis) for hypothesis in X_train['hypothesis']]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Train set\n",
    "axs[0].hist(train_prem_lengths, bins=20, alpha=0.6, label='Premise')\n",
    "axs[0].hist(train_hyp_lengths, bins=20, alpha=0.6, label='Hypothesis')\n",
    "axs[0].set_title(\"Train Set Length Distribution\")\n",
    "axs[0].set_xlabel(\"Number of Tokens\")\n",
    "axs[0].set_ylabel(\"Frequency\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Validation set\n",
    "axs[1].hist(val_prem_lengths, bins=20, alpha=0.6, label='Premise')\n",
    "axs[1].hist(val_hyp_lengths, bins=20, alpha=0.6, label='Hypothesis')\n",
    "axs[1].set_title(\"Validation Set Length Distribution\")\n",
    "axs[1].set_xlabel(\"Number of Tokens\")\n",
    "axs[1].set_ylabel(\"Frequency\")\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].hist(test_prem_lengths, bins=20, alpha=0.6, label='Premise')\n",
    "axs[2].hist(test_hyp_lengths, bins=20, alpha=0.6, label='Hypothesis')\n",
    "axs[2].set_title(\"Test Set Length Distribution\")\n",
    "axs[2].set_xlabel(\"Number of Tokens\")\n",
    "axs[2].set_ylabel(\"Frequency\")\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_-C0EzMvm42"
   },
   "source": [
    "### 1.6. Dataset Formation\n",
    "Now we create the training dataset. The tokenised premise and hypothesis sentences are encoded to be the index that corresponds to the word embedding in the embeddings table. Each sentence is then padded to be the same length as the longest respective premise or hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "HJENY7r0pLT5"
   },
   "outputs": [],
   "source": [
    "def encode_sentences(sentences):\n",
    "    encoded_sentences = []\n",
    "    for sentence in sentences:\n",
    "        encoded_sentences.append([wordindexes[word] if word in wordindexes else wordindexes['[OOV]'] for word in sentence])\n",
    "    return encoded_sentences\n",
    "\n",
    "def pad_sequences(sequences, max_length):\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < max_length:\n",
    "            padded_seq = seq + [wordindexes['[PAD]']] * (max_length - len(seq))\n",
    "        else:\n",
    "            padded_seq = seq[:max_length]\n",
    "        padded_sequences.append(padded_seq)\n",
    "    return padded_sequences\n",
    "\n",
    "max_prem = max(len(sentence) for sentence in X_train['premise'])\n",
    "max_hyp = max(len(sentence) for sentence in X_train['hypothesis'])\n",
    "encoded_prem_train = pad_sequences(encode_sentences(X_train['premise']), max_prem)\n",
    "encoded_hyp_train = pad_sequences(encode_sentences(X_train['hypothesis']), max_hyp)\n",
    "\n",
    "encoded_prem_val = pad_sequences(encode_sentences(X_val['premise']), max_prem)\n",
    "encoded_hyp_val = pad_sequences(encode_sentences(X_val['hypothesis']), max_hyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vE8QIkEwAab"
   },
   "source": [
    "The labels are now converted to 0 for neutral, and 1 for entails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "BlpRvN-uwGp6"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.map({'neutral': 0, 'entails': 1})\n",
    "y_val = y_val.map({'neutral': 0, 'entails': 1})\n",
    "y_test = y_test.map({'neutral': 0, 'entails': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6m0-kbudcfoN"
   },
   "source": [
    "Now we can create the dataset and data loaders for the train and validation set. To reduce the impact of the class imbalance in the train set, the number of neutral samples is reduced to the number of entails samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "rSSAM1oKXBSJ"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(torch.tensor(encoded_prem_train), torch.tensor(encoded_hyp_train), torch.tensor(y_train.values))\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "val_data = torch.utils.data.TensorDataset(torch.tensor(encoded_prem_val), torch.tensor(encoded_hyp_val), torch.tensor(y_val.values))\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: tensor([13914,  8284])\n",
      "Class weights: tensor([0.7464, 1.2536])\n"
     ]
    }
   ],
   "source": [
    "class_counts = torch.bincount(torch.tensor(y_train.values))\n",
    "class_weights = 1.0 / class_counts.float()\n",
    "class_weights = class_weights / class_weights.sum() * len(class_weights)\n",
    "\n",
    "print(f\"Class counts: {class_counts}\")\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Test Dataset\n",
    "Finally, we create the test dataset in a similar way the training and validation sets are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prem = max(len(sentence) for sentence in X_test['premise'])\n",
    "max_hyp = max(len(sentence) for sentence in X_test['hypothesis'])\n",
    "encoded_prem_test = pad_sequences(encode_sentences(X_test['premise']), max_prem)\n",
    "encoded_hyp_test = pad_sequences(encode_sentences(X_test['hypothesis']), max_hyp)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.tensor(encoded_prem_test), torch.tensor(encoded_hyp_test), torch.tensor(y_test.values))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GRU Model\n",
    "\n",
    "### 2.1. Training the Model\n",
    "This model is a Bidirectional GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRU(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, individual_dim=64, combined_dim=128, linear_dim=64, num_layers=4, dropout=0.4):\n",
    "        super(BiGRU, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(len(vocab), embedding_dim, padding_idx=wordindexes['[PAD]'])\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(emb_table))\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "\n",
    "        self.prem_gru = torch.nn.GRU(embedding_dim, individual_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.hyp_gru = torch.nn.GRU(embedding_dim, individual_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.prem_norm = torch.nn.LayerNorm(individual_dim * 2)\n",
    "        self.hyp_norm = torch.nn.LayerNorm(individual_dim * 2)\n",
    "\n",
    "        self.combined_gru = torch.nn.GRU(individual_dim * 2, combined_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.combined_norm = torch.nn.LayerNorm(combined_dim * 2)\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(combined_dim * 2, linear_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(linear_dim, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, prem, hyp):\n",
    "        prem = self.embeddings(prem)\n",
    "        hyp = self.embeddings(hyp)\n",
    "\n",
    "        prem_out, _ = self.prem_gru(prem)\n",
    "        hyp_out, _ = self.hyp_gru(hyp)\n",
    "        prem_out = self.prem_norm(prem_out)\n",
    "        hyp_out = self.hyp_norm(hyp_out)\n",
    "\n",
    "        merged_out = torch.cat((prem_out, hyp_out), dim=1)\n",
    "        merged_out, _ = self.combined_gru(merged_out)\n",
    "        merged_out = self.combined_norm(merged_out)\n",
    "        merged_out = torch.max(merged_out, dim=1)[0]\n",
    "\n",
    "        logits = self.mlp(merged_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimiser, scheduler, epochs, criterion, train_loader, val_loader, device):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            if i % 100 == 0:\n",
    "                sys.stdout.write(f\"\\rEpoch: ({(epoch + 1):02} / {epochs:02}) | Batch: ({i} / {len(train_loader)}) | Loss: {train_loss / (i+1)}\")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            premises = batch[0].to(device)\n",
    "            hypotheses = batch[1].to(device)\n",
    "            labels = batch[2].to(device).long()\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(premises, hypotheses)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "\n",
    "            for batch in val_loader:\n",
    "                premises = batch[0].to(device)\n",
    "                hypotheses = batch[1].to(device)\n",
    "                labels = batch[2].to(device).long()\n",
    "                outputs = model(premises, hypotheses)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "\n",
    "            val_loss = val_loss / len(val_loader)\n",
    "            val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "        epoch_time = (time.time() - start_time)\n",
    "        epoch_min = int(epoch_time // 60)\n",
    "        epoch_sec = int(epoch_time % 60)\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        sys.stdout.write(f\"\\rEpoch: ({(epoch + 1):02} / {epochs:02}) | Time: {epoch_min:02d}:{epoch_sec:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Accuracy: {val_acc:.2f}\\n\")\n",
    "    \n",
    "    # Return final validation loss\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform hyperparameter optimisation to find the parameters that achieve the highest performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing (0/81): (64, 64, 64, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:02 | Train Loss: 0.6934 | Val Loss: 0.6960 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:02 | Train Loss: 0.6903 | Val Loss: 0.6886 | Val Accuracy: 0.57\n",
      "Epoch: (03 / 05) | Time: 00:02 | Train Loss: 0.6893 | Val Loss: 0.6863 | Val Accuracy: 0.58\n",
      "Epoch: (04 / 05) | Time: 00:02 | Train Loss: 0.6862 | Val Loss: 0.6826 | Val Accuracy: 0.59\n",
      "Epoch: (05 / 05) | Time: 00:02 | Train Loss: 0.6829 | Val Loss: 0.6800 | Val Accuracy: 0.59\n",
      "Best Hyperparameters: [(64, 64, 64, 3, 0.4)] | Loss: 0.679953898702349\n",
      "Testing (1/81): (64, 64, 64, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6925 | Val Loss: 0.6994 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:02 | Train Loss: 0.6912 | Val Loss: 0.6956 | Val Accuracy: 0.50\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6899 | Val Loss: 0.6912 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6883 | Val Loss: 0.6876 | Val Accuracy: 0.55\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6851 | Val Loss: 0.6834 | Val Accuracy: 0.57\n",
      "Testing (2/81): (64, 64, 64, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6932 | Val Loss: 0.7041 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6915 | Val Loss: 0.6972 | Val Accuracy: 0.50\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6889 | Val Loss: 0.6927 | Val Accuracy: 0.52\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6875 | Val Loss: 0.6909 | Val Accuracy: 0.54\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6848 | Val Loss: 0.6881 | Val Accuracy: 0.56\n",
      "Testing (3/81): (64, 64, 128, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:02 | Train Loss: 0.6958 | Val Loss: 0.6879 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:02 | Train Loss: 0.6937 | Val Loss: 0.6916 | Val Accuracy: 0.57\n",
      "Epoch: (03 / 05) | Time: 00:02 | Train Loss: 0.6913 | Val Loss: 0.6917 | Val Accuracy: 0.54\n",
      "Epoch: (04 / 05) | Time: 00:02 | Train Loss: 0.6898 | Val Loss: 0.6874 | Val Accuracy: 0.61\n",
      "Epoch: (05 / 05) | Time: 00:02 | Train Loss: 0.6876 | Val Loss: 0.6852 | Val Accuracy: 0.60\n",
      "Testing (4/81): (64, 64, 128, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6933 | Val Loss: 0.6970 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6909 | Val Loss: 0.6930 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6887 | Val Loss: 0.6894 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6856 | Val Loss: 0.6864 | Val Accuracy: 0.56\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6809 | Val Loss: 0.6843 | Val Accuracy: 0.56\n",
      "Testing (5/81): (64, 64, 128, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6932 | Val Loss: 0.6976 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6914 | Val Loss: 0.6919 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6889 | Val Loss: 0.6879 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6847 | Val Loss: 0.6847 | Val Accuracy: 0.55\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6800 | Val Loss: 0.6813 | Val Accuracy: 0.57\n",
      "Testing (6/81): (64, 64, 256, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:02 | Train Loss: 0.6933 | Val Loss: 0.6919 | Val Accuracy: 0.57\n",
      "Epoch: (02 / 05) | Time: 00:02 | Train Loss: 0.6920 | Val Loss: 0.6893 | Val Accuracy: 0.59\n",
      "Epoch: (03 / 05) | Time: 00:02 | Train Loss: 0.6904 | Val Loss: 0.6878 | Val Accuracy: 0.59\n",
      "Epoch: (04 / 05) | Time: 00:02 | Train Loss: 0.6882 | Val Loss: 0.6847 | Val Accuracy: 0.60\n",
      "Epoch: (05 / 05) | Time: 00:02 | Train Loss: 0.6849 | Val Loss: 0.6799 | Val Accuracy: 0.61\n",
      "Best Hyperparameters: [(64, 64, 256, 3, 0.4)] | Loss: 0.6799012961841765\n",
      "Testing (7/81): (64, 64, 256, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6947 | Val Loss: 0.6907 | Val Accuracy: 0.60\n",
      "Epoch: (02 / 05) | Time: 00:02 | Train Loss: 0.6919 | Val Loss: 0.6900 | Val Accuracy: 0.59\n",
      "Epoch: (03 / 05) | Time: 00:02 | Train Loss: 0.6906 | Val Loss: 0.6868 | Val Accuracy: 0.59\n",
      "Epoch: (04 / 05) | Time: 00:02 | Train Loss: 0.6871 | Val Loss: 0.6817 | Val Accuracy: 0.59\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6819 | Val Loss: 0.6788 | Val Accuracy: 0.60\n",
      "Best Hyperparameters: [(64, 64, 256, 4, 0.4)] | Loss: 0.678809730779557\n",
      "Testing (8/81): (64, 64, 256, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6937 | Val Loss: 0.6949 | Val Accuracy: 0.49\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6920 | Val Loss: 0.6934 | Val Accuracy: 0.52\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6904 | Val Loss: 0.6889 | Val Accuracy: 0.57\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6866 | Val Loss: 0.6859 | Val Accuracy: 0.58\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6815 | Val Loss: 0.6823 | Val Accuracy: 0.58\n",
      "Testing (9/81): (64, 128, 64, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:02 | Train Loss: 0.6932 | Val Loss: 0.6940 | Val Accuracy: 0.51\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6911 | Val Loss: 0.6906 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:02 | Train Loss: 0.6887 | Val Loss: 0.6872 | Val Accuracy: 0.59\n",
      "Epoch: (04 / 05) | Time: 00:02 | Train Loss: 0.6857 | Val Loss: 0.6836 | Val Accuracy: 0.58\n",
      "Epoch: (05 / 05) | Time: 00:02 | Train Loss: 0.6807 | Val Loss: 0.6816 | Val Accuracy: 0.59\n",
      "Testing (10/81): (64, 128, 64, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6931 | Val Loss: 0.6960 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6915 | Val Loss: 0.6915 | Val Accuracy: 0.55\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6879 | Val Loss: 0.6875 | Val Accuracy: 0.57\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6813 | Val Loss: 0.6862 | Val Accuracy: 0.55\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6719 | Val Loss: 0.6803 | Val Accuracy: 0.58\n",
      "Testing (11/81): (64, 128, 64, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:04 | Train Loss: 0.6926 | Val Loss: 0.6963 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:04 | Train Loss: 0.6875 | Val Loss: 0.6895 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:04 | Train Loss: 0.6828 | Val Loss: 0.6859 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:04 | Train Loss: 0.6772 | Val Loss: 0.6823 | Val Accuracy: 0.58\n",
      "Epoch: (05 / 05) | Time: 00:04 | Train Loss: 0.6709 | Val Loss: 0.6773 | Val Accuracy: 0.58\n",
      "Best Hyperparameters: [(64, 128, 64, 5, 0.4)] | Loss: 0.6773200773057484\n",
      "Testing (12/81): (64, 128, 128, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:02 | Train Loss: 0.6928 | Val Loss: 0.6943 | Val Accuracy: 0.49\n",
      "Epoch: (02 / 05) | Time: 00:02 | Train Loss: 0.6909 | Val Loss: 0.6924 | Val Accuracy: 0.52\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6888 | Val Loss: 0.6879 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6854 | Val Loss: 0.6845 | Val Accuracy: 0.57\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6813 | Val Loss: 0.6829 | Val Accuracy: 0.57\n",
      "Testing (13/81): (64, 128, 128, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6935 | Val Loss: 0.6934 | Val Accuracy: 0.52\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6915 | Val Loss: 0.6919 | Val Accuracy: 0.55\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6884 | Val Loss: 0.6886 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6822 | Val Loss: 0.6867 | Val Accuracy: 0.56\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6722 | Val Loss: 0.6829 | Val Accuracy: 0.57\n",
      "Testing (14/81): (64, 128, 128, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:04 | Train Loss: 0.6938 | Val Loss: 0.6942 | Val Accuracy: 0.49\n",
      "Epoch: (02 / 05) | Time: 00:04 | Train Loss: 0.6912 | Val Loss: 0.6905 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:04 | Train Loss: 0.6848 | Val Loss: 0.6865 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:04 | Train Loss: 0.6735 | Val Loss: 0.6809 | Val Accuracy: 0.58\n",
      "Epoch: (05 / 05) | Time: 00:04 | Train Loss: 0.6590 | Val Loss: 0.6724 | Val Accuracy: 0.60\n",
      "Best Hyperparameters: [(64, 128, 128, 5, 0.4)] | Loss: 0.672430694103241\n",
      "Testing (15/81): (64, 128, 256, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:02 | Train Loss: 0.6942 | Val Loss: 0.6915 | Val Accuracy: 0.57\n",
      "Epoch: (02 / 05) | Time: 00:02 | Train Loss: 0.6907 | Val Loss: 0.6893 | Val Accuracy: 0.58\n",
      "Epoch: (03 / 05) | Time: 00:02 | Train Loss: 0.6871 | Val Loss: 0.6846 | Val Accuracy: 0.59\n",
      "Epoch: (04 / 05) | Time: 00:02 | Train Loss: 0.6805 | Val Loss: 0.6801 | Val Accuracy: 0.60\n",
      "Epoch: (05 / 05) | Time: 00:02 | Train Loss: 0.6722 | Val Loss: 0.6755 | Val Accuracy: 0.59\n",
      "Testing (16/81): (64, 128, 256, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6939 | Val Loss: 0.6939 | Val Accuracy: 0.51\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6915 | Val Loss: 0.6912 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6878 | Val Loss: 0.6875 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6806 | Val Loss: 0.6852 | Val Accuracy: 0.56\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6705 | Val Loss: 0.6788 | Val Accuracy: 0.58\n",
      "Testing (17/81): (64, 128, 256, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:04 | Train Loss: 0.6930 | Val Loss: 0.6958 | Val Accuracy: 0.49\n",
      "Epoch: (02 / 05) | Time: 00:04 | Train Loss: 0.6905 | Val Loss: 0.6907 | Val Accuracy: 0.53\n",
      "Epoch: (03 / 05) | Time: 00:04 | Train Loss: 0.6842 | Val Loss: 0.6898 | Val Accuracy: 0.54\n",
      "Epoch: (04 / 05) | Time: 00:04 | Train Loss: 0.6744 | Val Loss: 0.6880 | Val Accuracy: 0.56\n",
      "Epoch: (05 / 05) | Time: 00:04 | Train Loss: 0.6642 | Val Loss: 0.6780 | Val Accuracy: 0.58\n",
      "Testing (18/81): (64, 256, 64, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:09 | Train Loss: 0.6916 | Val Loss: 0.6921 | Val Accuracy: 0.54\n",
      "Epoch: (02 / 05) | Time: 00:09 | Train Loss: 0.6878 | Val Loss: 0.6878 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:09 | Train Loss: 0.6807 | Val Loss: 0.6849 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:09 | Train Loss: 0.6710 | Val Loss: 0.6781 | Val Accuracy: 0.58\n",
      "Epoch: (05 / 05) | Time: 00:09 | Train Loss: 0.6592 | Val Loss: 0.6711 | Val Accuracy: 0.60\n",
      "Best Hyperparameters: [(64, 256, 64, 3, 0.4)] | Loss: 0.6710646691776457\n",
      "Testing (19/81): (64, 256, 64, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:12 | Train Loss: 0.6915 | Val Loss: 0.6925 | Val Accuracy: 0.53\n",
      "Epoch: (02 / 05) | Time: 00:12 | Train Loss: 0.6861 | Val Loss: 0.6946 | Val Accuracy: 0.53\n",
      "Epoch: (03 / 05) | Time: 00:12 | Train Loss: 0.6799 | Val Loss: 0.6933 | Val Accuracy: 0.54\n",
      "Epoch: (04 / 05) | Time: 00:12 | Train Loss: 0.6736 | Val Loss: 0.6892 | Val Accuracy: 0.57\n",
      "Epoch: (05 / 05) | Time: 00:12 | Train Loss: 0.6631 | Val Loss: 0.6779 | Val Accuracy: 0.58\n",
      "Testing (20/81): (64, 256, 64, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:15 | Train Loss: 0.6923 | Val Loss: 0.6951 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:15 | Train Loss: 0.6870 | Val Loss: 0.6926 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:15 | Train Loss: 0.6783 | Val Loss: 0.6914 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:14 | Train Loss: 0.6675 | Val Loss: 0.6829 | Val Accuracy: 0.57\n",
      "Epoch: (05 / 05) | Time: 00:14 | Train Loss: 0.6570 | Val Loss: 0.6691 | Val Accuracy: 0.61\n",
      "Best Hyperparameters: [(64, 256, 64, 5, 0.4)] | Loss: 0.6690807456061953\n",
      "Testing (21/81): (64, 256, 128, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:08 | Train Loss: 0.6928 | Val Loss: 0.6953 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:08 | Train Loss: 0.6908 | Val Loss: 0.6912 | Val Accuracy: 0.55\n",
      "Epoch: (03 / 05) | Time: 00:09 | Train Loss: 0.6858 | Val Loss: 0.6905 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:09 | Train Loss: 0.6760 | Val Loss: 0.6874 | Val Accuracy: 0.55\n",
      "Epoch: (05 / 05) | Time: 00:09 | Train Loss: 0.6639 | Val Loss: 0.6782 | Val Accuracy: 0.58\n",
      "Testing (22/81): (64, 256, 128, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:12 | Train Loss: 0.6917 | Val Loss: 0.6924 | Val Accuracy: 0.54\n",
      "Epoch: (02 / 05) | Time: 00:12 | Train Loss: 0.6867 | Val Loss: 0.6923 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:12 | Train Loss: 0.6789 | Val Loss: 0.6890 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:11 | Train Loss: 0.6692 | Val Loss: 0.6825 | Val Accuracy: 0.58\n",
      "Epoch: (05 / 05) | Time: 00:12 | Train Loss: 0.6606 | Val Loss: 0.6749 | Val Accuracy: 0.60\n",
      "Testing (23/81): (64, 256, 128, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:15 | Train Loss: 0.6930 | Val Loss: 0.6939 | Val Accuracy: 0.53\n",
      "Epoch: (02 / 05) | Time: 00:14 | Train Loss: 0.6862 | Val Loss: 0.6939 | Val Accuracy: 0.53\n",
      "Epoch: (03 / 05) | Time: 00:15 | Train Loss: 0.6767 | Val Loss: 0.6936 | Val Accuracy: 0.54\n",
      "Epoch: (04 / 05) | Time: 00:15 | Train Loss: 0.6664 | Val Loss: 0.6879 | Val Accuracy: 0.57\n",
      "Epoch: (05 / 05) | Time: 00:16 | Train Loss: 0.6577 | Val Loss: 0.6800 | Val Accuracy: 0.59\n",
      "Testing (24/81): (64, 256, 256, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:09 | Train Loss: 0.6918 | Val Loss: 0.6916 | Val Accuracy: 0.56\n",
      "Epoch: (02 / 05) | Time: 00:09 | Train Loss: 0.6881 | Val Loss: 0.6898 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:09 | Train Loss: 0.6809 | Val Loss: 0.6920 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:10 | Train Loss: 0.6712 | Val Loss: 0.6870 | Val Accuracy: 0.57\n",
      "Epoch: (05 / 05) | Time: 00:09 | Train Loss: 0.6619 | Val Loss: 0.6812 | Val Accuracy: 0.58\n",
      "Testing (25/81): (64, 256, 256, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:13 | Train Loss: 0.6931 | Val Loss: 0.6946 | Val Accuracy: 0.51\n",
      "Epoch: (02 / 05) | Time: 00:14 | Train Loss: 0.6895 | Val Loss: 0.6945 | Val Accuracy: 0.53\n",
      "Epoch: (03 / 05) | Time: 00:12 | Train Loss: 0.6825 | Val Loss: 0.6968 | Val Accuracy: 0.54\n",
      "Epoch: (04 / 05) | Time: 00:13 | Train Loss: 0.6728 | Val Loss: 0.6923 | Val Accuracy: 0.56\n",
      "Epoch: (05 / 05) | Time: 00:12 | Train Loss: 0.6622 | Val Loss: 0.6873 | Val Accuracy: 0.58\n",
      "Testing (26/81): (64, 256, 256, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:15 | Train Loss: 0.6918 | Val Loss: 0.6953 | Val Accuracy: 0.52\n",
      "Epoch: (02 / 05) | Time: 00:15 | Train Loss: 0.6846 | Val Loss: 0.6924 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:15 | Train Loss: 0.6738 | Val Loss: 0.6856 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:16 | Train Loss: 0.6625 | Val Loss: 0.6778 | Val Accuracy: 0.59\n",
      "Epoch: (05 / 05) | Time: 00:15 | Train Loss: 0.6508 | Val Loss: 0.6693 | Val Accuracy: 0.61\n",
      "Testing (27/81): (128, 64, 64, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:02 | Train Loss: 0.6920 | Val Loss: 0.6933 | Val Accuracy: 0.53\n",
      "Epoch: (02 / 05) | Time: 00:02 | Train Loss: 0.6890 | Val Loss: 0.6889 | Val Accuracy: 0.59\n",
      "Epoch: (03 / 05) | Time: 00:02 | Train Loss: 0.6864 | Val Loss: 0.6838 | Val Accuracy: 0.60\n",
      "Epoch: (04 / 05) | Time: 00:02 | Train Loss: 0.6820 | Val Loss: 0.6795 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:02 | Train Loss: 0.6764 | Val Loss: 0.6741 | Val Accuracy: 0.62\n",
      "Testing (28/81): (128, 64, 64, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6921 | Val Loss: 0.6952 | Val Accuracy: 0.51\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6884 | Val Loss: 0.6910 | Val Accuracy: 0.55\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6847 | Val Loss: 0.6892 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6793 | Val Loss: 0.6851 | Val Accuracy: 0.56\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6711 | Val Loss: 0.6770 | Val Accuracy: 0.59\n",
      "Testing (29/81): (128, 64, 64, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:04 | Train Loss: 0.6931 | Val Loss: 0.6989 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:04 | Train Loss: 0.6888 | Val Loss: 0.6924 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:04 | Train Loss: 0.6848 | Val Loss: 0.6916 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:04 | Train Loss: 0.6790 | Val Loss: 0.6868 | Val Accuracy: 0.57\n",
      "Epoch: (05 / 05) | Time: 00:04 | Train Loss: 0.6680 | Val Loss: 0.6665 | Val Accuracy: 0.64\n",
      "Best Hyperparameters: [(128, 64, 64, 5, 0.4)] | Loss: 0.6665016696566627\n",
      "Testing (30/81): (128, 64, 128, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:02 | Train Loss: 0.6926 | Val Loss: 0.6925 | Val Accuracy: 0.54\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6897 | Val Loss: 0.6885 | Val Accuracy: 0.57\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6868 | Val Loss: 0.6844 | Val Accuracy: 0.58\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6824 | Val Loss: 0.6825 | Val Accuracy: 0.59\n",
      "Epoch: (05 / 05) | Time: 00:02 | Train Loss: 0.6759 | Val Loss: 0.6778 | Val Accuracy: 0.59\n",
      "Testing (31/81): (128, 64, 128, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6931 | Val Loss: 0.6881 | Val Accuracy: 0.57\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6888 | Val Loss: 0.6858 | Val Accuracy: 0.59\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6835 | Val Loss: 0.6830 | Val Accuracy: 0.59\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6752 | Val Loss: 0.6778 | Val Accuracy: 0.59\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6633 | Val Loss: 0.6606 | Val Accuracy: 0.62\n",
      "Best Hyperparameters: [(128, 64, 128, 4, 0.4)] | Loss: 0.6606344268435523\n",
      "Testing (32/81): (128, 64, 128, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:04 | Train Loss: 0.6925 | Val Loss: 0.6925 | Val Accuracy: 0.54\n",
      "Epoch: (02 / 05) | Time: 00:04 | Train Loss: 0.6892 | Val Loss: 0.6903 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:04 | Train Loss: 0.6853 | Val Loss: 0.6888 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6795 | Val Loss: 0.6864 | Val Accuracy: 0.56\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6713 | Val Loss: 0.6774 | Val Accuracy: 0.59\n",
      "Testing (33/81): (128, 64, 256, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:02 | Train Loss: 0.6945 | Val Loss: 0.6906 | Val Accuracy: 0.60\n",
      "Epoch: (02 / 05) | Time: 00:02 | Train Loss: 0.6920 | Val Loss: 0.6894 | Val Accuracy: 0.57\n",
      "Epoch: (03 / 05) | Time: 00:02 | Train Loss: 0.6891 | Val Loss: 0.6876 | Val Accuracy: 0.57\n",
      "Epoch: (04 / 05) | Time: 00:02 | Train Loss: 0.6852 | Val Loss: 0.6860 | Val Accuracy: 0.57\n",
      "Epoch: (05 / 05) | Time: 00:02 | Train Loss: 0.6796 | Val Loss: 0.6832 | Val Accuracy: 0.58\n",
      "Testing (34/81): (128, 64, 256, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6942 | Val Loss: 0.6920 | Val Accuracy: 0.54\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6894 | Val Loss: 0.6907 | Val Accuracy: 0.55\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6856 | Val Loss: 0.6875 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6795 | Val Loss: 0.6848 | Val Accuracy: 0.57\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6701 | Val Loss: 0.6752 | Val Accuracy: 0.60\n",
      "Testing (35/81): (128, 64, 256, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:04 | Train Loss: 0.6933 | Val Loss: 0.6899 | Val Accuracy: 0.55\n",
      "Epoch: (02 / 05) | Time: 00:04 | Train Loss: 0.6899 | Val Loss: 0.6895 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:04 | Train Loss: 0.6841 | Val Loss: 0.6870 | Val Accuracy: 0.57\n",
      "Epoch: (04 / 05) | Time: 00:04 | Train Loss: 0.6752 | Val Loss: 0.6749 | Val Accuracy: 0.59\n",
      "Epoch: (05 / 05) | Time: 00:04 | Train Loss: 0.6624 | Val Loss: 0.6554 | Val Accuracy: 0.62\n",
      "Best Hyperparameters: [(128, 64, 256, 5, 0.4)] | Loss: 0.6553728807540167\n",
      "Testing (36/81): (128, 128, 64, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6927 | Val Loss: 0.6919 | Val Accuracy: 0.56\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6900 | Val Loss: 0.6899 | Val Accuracy: 0.57\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6857 | Val Loss: 0.6887 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6779 | Val Loss: 0.6831 | Val Accuracy: 0.56\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6666 | Val Loss: 0.6701 | Val Accuracy: 0.60\n",
      "Testing (37/81): (128, 128, 64, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:04 | Train Loss: 0.6920 | Val Loss: 0.6981 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:04 | Train Loss: 0.6878 | Val Loss: 0.6899 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:04 | Train Loss: 0.6823 | Val Loss: 0.6874 | Val Accuracy: 0.54\n",
      "Epoch: (04 / 05) | Time: 00:04 | Train Loss: 0.6731 | Val Loss: 0.6778 | Val Accuracy: 0.58\n",
      "Epoch: (05 / 05) | Time: 00:04 | Train Loss: 0.6614 | Val Loss: 0.6637 | Val Accuracy: 0.61\n",
      "Testing (38/81): (128, 128, 64, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:05 | Train Loss: 0.6919 | Val Loss: 0.6937 | Val Accuracy: 0.52\n",
      "Epoch: (02 / 05) | Time: 00:05 | Train Loss: 0.6873 | Val Loss: 0.6935 | Val Accuracy: 0.53\n",
      "Epoch: (03 / 05) | Time: 00:05 | Train Loss: 0.6804 | Val Loss: 0.6893 | Val Accuracy: 0.54\n",
      "Epoch: (04 / 05) | Time: 00:05 | Train Loss: 0.6693 | Val Loss: 0.6769 | Val Accuracy: 0.59\n",
      "Epoch: (05 / 05) | Time: 00:05 | Train Loss: 0.6534 | Val Loss: 0.6672 | Val Accuracy: 0.60\n",
      "Testing (39/81): (128, 128, 128, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6935 | Val Loss: 0.6892 | Val Accuracy: 0.58\n",
      "Epoch: (02 / 05) | Time: 00:04 | Train Loss: 0.6895 | Val Loss: 0.6856 | Val Accuracy: 0.58\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6847 | Val Loss: 0.6828 | Val Accuracy: 0.59\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6767 | Val Loss: 0.6819 | Val Accuracy: 0.57\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6674 | Val Loss: 0.6735 | Val Accuracy: 0.59\n",
      "Testing (40/81): (128, 128, 128, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:04 | Train Loss: 0.6941 | Val Loss: 0.6916 | Val Accuracy: 0.55\n",
      "Epoch: (02 / 05) | Time: 00:04 | Train Loss: 0.6904 | Val Loss: 0.6899 | Val Accuracy: 0.55\n",
      "Epoch: (03 / 05) | Time: 00:04 | Train Loss: 0.6832 | Val Loss: 0.6903 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:04 | Train Loss: 0.6721 | Val Loss: 0.6795 | Val Accuracy: 0.58\n",
      "Epoch: (05 / 05) | Time: 00:04 | Train Loss: 0.6571 | Val Loss: 0.6652 | Val Accuracy: 0.61\n",
      "Testing (41/81): (128, 128, 128, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:05 | Train Loss: 0.6921 | Val Loss: 0.6939 | Val Accuracy: 0.52\n",
      "Epoch: (02 / 05) | Time: 00:05 | Train Loss: 0.6866 | Val Loss: 0.6910 | Val Accuracy: 0.53\n",
      "Epoch: (03 / 05) | Time: 00:05 | Train Loss: 0.6774 | Val Loss: 0.6810 | Val Accuracy: 0.58\n",
      "Epoch: (04 / 05) | Time: 00:04 | Train Loss: 0.6636 | Val Loss: 0.6665 | Val Accuracy: 0.61\n",
      "Epoch: (05 / 05) | Time: 00:05 | Train Loss: 0.6481 | Val Loss: 0.6546 | Val Accuracy: 0.63\n",
      "Best Hyperparameters: [(128, 128, 128, 5, 0.4)] | Loss: 0.6545820349738711\n",
      "Testing (42/81): (128, 128, 256, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:03 | Train Loss: 0.6928 | Val Loss: 0.6924 | Val Accuracy: 0.54\n",
      "Epoch: (02 / 05) | Time: 00:03 | Train Loss: 0.6888 | Val Loss: 0.6863 | Val Accuracy: 0.58\n",
      "Epoch: (03 / 05) | Time: 00:03 | Train Loss: 0.6831 | Val Loss: 0.6821 | Val Accuracy: 0.58\n",
      "Epoch: (04 / 05) | Time: 00:03 | Train Loss: 0.6736 | Val Loss: 0.6782 | Val Accuracy: 0.58\n",
      "Epoch: (05 / 05) | Time: 00:03 | Train Loss: 0.6601 | Val Loss: 0.6609 | Val Accuracy: 0.62\n",
      "Testing (43/81): (128, 128, 256, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:04 | Train Loss: 0.6921 | Val Loss: 0.6907 | Val Accuracy: 0.55\n",
      "Epoch: (02 / 05) | Time: 00:04 | Train Loss: 0.6882 | Val Loss: 0.6888 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:04 | Train Loss: 0.6823 | Val Loss: 0.6876 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:04 | Train Loss: 0.6708 | Val Loss: 0.6775 | Val Accuracy: 0.59\n",
      "Epoch: (05 / 05) | Time: 00:04 | Train Loss: 0.6544 | Val Loss: 0.6562 | Val Accuracy: 0.62\n",
      "Testing (44/81): (128, 128, 256, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:05 | Train Loss: 0.6930 | Val Loss: 0.6936 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:05 | Train Loss: 0.6897 | Val Loss: 0.6905 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:05 | Train Loss: 0.6818 | Val Loss: 0.6883 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:05 | Train Loss: 0.6662 | Val Loss: 0.6663 | Val Accuracy: 0.60\n",
      "Epoch: (05 / 05) | Time: 00:05 | Train Loss: 0.6474 | Val Loss: 0.6405 | Val Accuracy: 0.64\n",
      "Best Hyperparameters: [(128, 128, 256, 5, 0.4)] | Loss: 0.640519917011261\n",
      "Testing (45/81): (128, 256, 64, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:08 | Train Loss: 0.6930 | Val Loss: 0.6910 | Val Accuracy: 0.56\n",
      "Epoch: (02 / 05) | Time: 00:08 | Train Loss: 0.6869 | Val Loss: 0.6889 | Val Accuracy: 0.55\n",
      "Epoch: (03 / 05) | Time: 00:08 | Train Loss: 0.6787 | Val Loss: 0.6813 | Val Accuracy: 0.57\n",
      "Epoch: (04 / 05) | Time: 00:09 | Train Loss: 0.6663 | Val Loss: 0.6676 | Val Accuracy: 0.60\n",
      "Epoch: (05 / 05) | Time: 00:10 | Train Loss: 0.6526 | Val Loss: 0.6528 | Val Accuracy: 0.62\n",
      "Testing (46/81): (128, 256, 64, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:13 | Train Loss: 0.6939 | Val Loss: 0.6931 | Val Accuracy: 0.51\n",
      "Epoch: (02 / 05) | Time: 00:13 | Train Loss: 0.6867 | Val Loss: 0.6963 | Val Accuracy: 0.51\n",
      "Epoch: (03 / 05) | Time: 00:13 | Train Loss: 0.6757 | Val Loss: 0.6883 | Val Accuracy: 0.55\n",
      "Epoch: (04 / 05) | Time: 00:13 | Train Loss: 0.6634 | Val Loss: 0.6759 | Val Accuracy: 0.59\n",
      "Epoch: (05 / 05) | Time: 00:12 | Train Loss: 0.6484 | Val Loss: 0.6605 | Val Accuracy: 0.62\n",
      "Testing (47/81): (128, 256, 64, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:15 | Train Loss: 0.6888 | Val Loss: 0.6954 | Val Accuracy: 0.53\n",
      "Epoch: (02 / 05) | Time: 00:14 | Train Loss: 0.6810 | Val Loss: 0.6841 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:14 | Train Loss: 0.6681 | Val Loss: 0.6770 | Val Accuracy: 0.59\n",
      "Epoch: (04 / 05) | Time: 00:14 | Train Loss: 0.6512 | Val Loss: 0.6617 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:14 | Train Loss: 0.6378 | Val Loss: 0.6356 | Val Accuracy: 0.66\n",
      "Best Hyperparameters: [(128, 256, 64, 5, 0.4)] | Loss: 0.6356494682175773\n",
      "Testing (48/81): (128, 256, 128, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:08 | Train Loss: 0.6915 | Val Loss: 0.6917 | Val Accuracy: 0.55\n",
      "Epoch: (02 / 05) | Time: 00:09 | Train Loss: 0.6860 | Val Loss: 0.6891 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:08 | Train Loss: 0.6779 | Val Loss: 0.6830 | Val Accuracy: 0.57\n",
      "Epoch: (04 / 05) | Time: 00:09 | Train Loss: 0.6655 | Val Loss: 0.6702 | Val Accuracy: 0.59\n",
      "Epoch: (05 / 05) | Time: 00:09 | Train Loss: 0.6488 | Val Loss: 0.6583 | Val Accuracy: 0.62\n",
      "Testing (49/81): (128, 256, 128, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:12 | Train Loss: 0.6909 | Val Loss: 0.6925 | Val Accuracy: 0.55\n",
      "Epoch: (02 / 05) | Time: 00:12 | Train Loss: 0.6822 | Val Loss: 0.6835 | Val Accuracy: 0.57\n",
      "Epoch: (03 / 05) | Time: 00:12 | Train Loss: 0.6667 | Val Loss: 0.6690 | Val Accuracy: 0.60\n",
      "Epoch: (04 / 05) | Time: 00:12 | Train Loss: 0.6505 | Val Loss: 0.6537 | Val Accuracy: 0.63\n",
      "Epoch: (05 / 05) | Time: 00:13 | Train Loss: 0.6351 | Val Loss: 0.6343 | Val Accuracy: 0.66\n",
      "Best Hyperparameters: [(128, 256, 128, 4, 0.4)] | Loss: 0.6342527667681376\n",
      "Testing (50/81): (128, 256, 128, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:15 | Train Loss: 0.6919 | Val Loss: 0.6941 | Val Accuracy: 0.52\n",
      "Epoch: (02 / 05) | Time: 00:15 | Train Loss: 0.6830 | Val Loss: 0.6925 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:15 | Train Loss: 0.6717 | Val Loss: 0.6839 | Val Accuracy: 0.57\n",
      "Epoch: (04 / 05) | Time: 00:15 | Train Loss: 0.6569 | Val Loss: 0.6666 | Val Accuracy: 0.60\n",
      "Epoch: (05 / 05) | Time: 00:15 | Train Loss: 0.6410 | Val Loss: 0.6451 | Val Accuracy: 0.64\n",
      "Testing (51/81): (128, 256, 256, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:09 | Train Loss: 0.6913 | Val Loss: 0.6916 | Val Accuracy: 0.54\n",
      "Epoch: (02 / 05) | Time: 00:09 | Train Loss: 0.6843 | Val Loss: 0.6935 | Val Accuracy: 0.53\n",
      "Epoch: (03 / 05) | Time: 00:09 | Train Loss: 0.6730 | Val Loss: 0.6845 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:10 | Train Loss: 0.6588 | Val Loss: 0.6730 | Val Accuracy: 0.61\n",
      "Epoch: (05 / 05) | Time: 00:10 | Train Loss: 0.6449 | Val Loss: 0.6568 | Val Accuracy: 0.63\n",
      "Testing (52/81): (128, 256, 256, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:12 | Train Loss: 0.6922 | Val Loss: 0.6930 | Val Accuracy: 0.53\n",
      "Epoch: (02 / 05) | Time: 00:12 | Train Loss: 0.6852 | Val Loss: 0.6917 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:12 | Train Loss: 0.6729 | Val Loss: 0.6848 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:11 | Train Loss: 0.6582 | Val Loss: 0.6796 | Val Accuracy: 0.59\n",
      "Epoch: (05 / 05) | Time: 00:12 | Train Loss: 0.6443 | Val Loss: 0.6628 | Val Accuracy: 0.63\n",
      "Testing (53/81): (128, 256, 256, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:15 | Train Loss: 0.6918 | Val Loss: 0.6970 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:15 | Train Loss: 0.6834 | Val Loss: 0.6933 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:15 | Train Loss: 0.6705 | Val Loss: 0.6821 | Val Accuracy: 0.58\n",
      "Epoch: (04 / 05) | Time: 00:15 | Train Loss: 0.6558 | Val Loss: 0.6649 | Val Accuracy: 0.63\n",
      "Epoch: (05 / 05) | Time: 00:15 | Train Loss: 0.6378 | Val Loss: 0.6403 | Val Accuracy: 0.66\n",
      "Testing (54/81): (256, 64, 64, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:08 | Train Loss: 0.6941 | Val Loss: 0.6895 | Val Accuracy: 0.62\n",
      "Epoch: (02 / 05) | Time: 00:09 | Train Loss: 0.6901 | Val Loss: 0.6854 | Val Accuracy: 0.61\n",
      "Epoch: (03 / 05) | Time: 00:08 | Train Loss: 0.6856 | Val Loss: 0.6798 | Val Accuracy: 0.61\n",
      "Epoch: (04 / 05) | Time: 00:08 | Train Loss: 0.6780 | Val Loss: 0.6660 | Val Accuracy: 0.63\n",
      "Epoch: (05 / 05) | Time: 00:09 | Train Loss: 0.6684 | Val Loss: 0.6528 | Val Accuracy: 0.66\n",
      "Testing (55/81): (256, 64, 64, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:12 | Train Loss: 0.6896 | Val Loss: 0.6926 | Val Accuracy: 0.55\n",
      "Epoch: (02 / 05) | Time: 00:11 | Train Loss: 0.6834 | Val Loss: 0.6860 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:12 | Train Loss: 0.6715 | Val Loss: 0.6757 | Val Accuracy: 0.61\n",
      "Epoch: (04 / 05) | Time: 00:11 | Train Loss: 0.6572 | Val Loss: 0.6640 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:13 | Train Loss: 0.6446 | Val Loss: 0.6440 | Val Accuracy: 0.65\n",
      "Testing (56/81): (256, 64, 64, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:16 | Train Loss: 0.6919 | Val Loss: 0.6941 | Val Accuracy: 0.51\n",
      "Epoch: (02 / 05) | Time: 00:16 | Train Loss: 0.6874 | Val Loss: 0.6919 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:16 | Train Loss: 0.6783 | Val Loss: 0.6773 | Val Accuracy: 0.59\n",
      "Epoch: (04 / 05) | Time: 00:15 | Train Loss: 0.6652 | Val Loss: 0.6625 | Val Accuracy: 0.61\n",
      "Epoch: (05 / 05) | Time: 00:16 | Train Loss: 0.6498 | Val Loss: 0.6552 | Val Accuracy: 0.64\n",
      "Testing (57/81): (256, 64, 128, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:09 | Train Loss: 0.6918 | Val Loss: 0.6930 | Val Accuracy: 0.52\n",
      "Epoch: (02 / 05) | Time: 00:09 | Train Loss: 0.6879 | Val Loss: 0.6905 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:09 | Train Loss: 0.6828 | Val Loss: 0.6840 | Val Accuracy: 0.58\n",
      "Epoch: (04 / 05) | Time: 00:09 | Train Loss: 0.6752 | Val Loss: 0.6733 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:11 | Train Loss: 0.6642 | Val Loss: 0.6526 | Val Accuracy: 0.64\n",
      "Testing (58/81): (256, 64, 128, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:12 | Train Loss: 0.6914 | Val Loss: 0.6959 | Val Accuracy: 0.51\n",
      "Epoch: (02 / 05) | Time: 00:12 | Train Loss: 0.6840 | Val Loss: 0.6910 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:12 | Train Loss: 0.6756 | Val Loss: 0.6759 | Val Accuracy: 0.60\n",
      "Epoch: (04 / 05) | Time: 00:12 | Train Loss: 0.6617 | Val Loss: 0.6680 | Val Accuracy: 0.61\n",
      "Epoch: (05 / 05) | Time: 00:12 | Train Loss: 0.6479 | Val Loss: 0.6484 | Val Accuracy: 0.64\n",
      "Testing (59/81): (256, 64, 128, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:15 | Train Loss: 0.6916 | Val Loss: 0.6976 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:14 | Train Loss: 0.6875 | Val Loss: 0.6934 | Val Accuracy: 0.53\n",
      "Epoch: (03 / 05) | Time: 00:16 | Train Loss: 0.6794 | Val Loss: 0.6757 | Val Accuracy: 0.60\n",
      "Epoch: (04 / 05) | Time: 00:16 | Train Loss: 0.6639 | Val Loss: 0.6645 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:14 | Train Loss: 0.6498 | Val Loss: 0.6437 | Val Accuracy: 0.64\n",
      "Testing (60/81): (256, 64, 256, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:08 | Train Loss: 0.6930 | Val Loss: 0.6896 | Val Accuracy: 0.56\n",
      "Epoch: (02 / 05) | Time: 00:08 | Train Loss: 0.6858 | Val Loss: 0.6856 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:08 | Train Loss: 0.6781 | Val Loss: 0.6763 | Val Accuracy: 0.59\n",
      "Epoch: (04 / 05) | Time: 00:08 | Train Loss: 0.6660 | Val Loss: 0.6615 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:08 | Train Loss: 0.6504 | Val Loss: 0.6419 | Val Accuracy: 0.64\n",
      "Testing (61/81): (256, 64, 256, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:11 | Train Loss: 0.6911 | Val Loss: 0.6906 | Val Accuracy: 0.54\n",
      "Epoch: (02 / 05) | Time: 00:11 | Train Loss: 0.6821 | Val Loss: 0.6823 | Val Accuracy: 0.58\n",
      "Epoch: (03 / 05) | Time: 00:11 | Train Loss: 0.6694 | Val Loss: 0.6724 | Val Accuracy: 0.61\n",
      "Epoch: (04 / 05) | Time: 00:11 | Train Loss: 0.6559 | Val Loss: 0.6595 | Val Accuracy: 0.63\n",
      "Epoch: (05 / 05) | Time: 00:11 | Train Loss: 0.6410 | Val Loss: 0.6487 | Val Accuracy: 0.63\n",
      "Testing (62/81): (256, 64, 256, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:14 | Train Loss: 0.6917 | Val Loss: 0.6954 | Val Accuracy: 0.51\n",
      "Epoch: (02 / 05) | Time: 00:14 | Train Loss: 0.6852 | Val Loss: 0.6925 | Val Accuracy: 0.53\n",
      "Epoch: (03 / 05) | Time: 00:14 | Train Loss: 0.6775 | Val Loss: 0.6775 | Val Accuracy: 0.58\n",
      "Epoch: (04 / 05) | Time: 00:16 | Train Loss: 0.6649 | Val Loss: 0.6676 | Val Accuracy: 0.61\n",
      "Epoch: (05 / 05) | Time: 00:16 | Train Loss: 0.6500 | Val Loss: 0.6514 | Val Accuracy: 0.64\n",
      "Testing (63/81): (256, 128, 64, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:10 | Train Loss: 0.6918 | Val Loss: 0.6918 | Val Accuracy: 0.54\n",
      "Epoch: (02 / 05) | Time: 00:10 | Train Loss: 0.6857 | Val Loss: 0.6896 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:10 | Train Loss: 0.6777 | Val Loss: 0.6780 | Val Accuracy: 0.60\n",
      "Epoch: (04 / 05) | Time: 00:11 | Train Loss: 0.6639 | Val Loss: 0.6656 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:10 | Train Loss: 0.6488 | Val Loss: 0.6546 | Val Accuracy: 0.63\n",
      "Testing (64/81): (256, 128, 64, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:13 | Train Loss: 0.6909 | Val Loss: 0.6954 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:14 | Train Loss: 0.6845 | Val Loss: 0.6940 | Val Accuracy: 0.52\n",
      "Epoch: (03 / 05) | Time: 00:14 | Train Loss: 0.6748 | Val Loss: 0.6854 | Val Accuracy: 0.56\n",
      "Epoch: (04 / 05) | Time: 00:14 | Train Loss: 0.6597 | Val Loss: 0.6689 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:15 | Train Loss: 0.6413 | Val Loss: 0.6564 | Val Accuracy: 0.63\n",
      "Testing (65/81): (256, 128, 64, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:17 | Train Loss: 0.6933 | Val Loss: 0.6944 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:18 | Train Loss: 0.6865 | Val Loss: 0.6890 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:17 | Train Loss: 0.6736 | Val Loss: 0.6792 | Val Accuracy: 0.58\n",
      "Epoch: (04 / 05) | Time: 00:17 | Train Loss: 0.6554 | Val Loss: 0.6516 | Val Accuracy: 0.63\n",
      "Epoch: (05 / 05) | Time: 00:18 | Train Loss: 0.6380 | Val Loss: 0.6313 | Val Accuracy: 0.66\n",
      "Best Hyperparameters: [(256, 128, 64, 5, 0.4)] | Loss: 0.6313026831263587\n",
      "Testing (66/81): (256, 128, 128, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:10 | Train Loss: 0.6913 | Val Loss: 0.6925 | Val Accuracy: 0.52\n",
      "Epoch: (02 / 05) | Time: 00:09 | Train Loss: 0.6859 | Val Loss: 0.6902 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:09 | Train Loss: 0.6767 | Val Loss: 0.6789 | Val Accuracy: 0.58\n",
      "Epoch: (04 / 05) | Time: 00:09 | Train Loss: 0.6602 | Val Loss: 0.6593 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:09 | Train Loss: 0.6429 | Val Loss: 0.6431 | Val Accuracy: 0.64\n",
      "Testing (67/81): (256, 128, 128, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:13 | Train Loss: 0.6920 | Val Loss: 0.6917 | Val Accuracy: 0.54\n",
      "Epoch: (02 / 05) | Time: 00:13 | Train Loss: 0.6847 | Val Loss: 0.6862 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:13 | Train Loss: 0.6716 | Val Loss: 0.6719 | Val Accuracy: 0.59\n",
      "Epoch: (04 / 05) | Time: 00:12 | Train Loss: 0.6529 | Val Loss: 0.6602 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:13 | Train Loss: 0.6355 | Val Loss: 0.6363 | Val Accuracy: 0.66\n",
      "Testing (68/81): (256, 128, 128, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:16 | Train Loss: 0.6910 | Val Loss: 0.6961 | Val Accuracy: 0.51\n",
      "Epoch: (02 / 05) | Time: 00:17 | Train Loss: 0.6827 | Val Loss: 0.6898 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:15 | Train Loss: 0.6682 | Val Loss: 0.6878 | Val Accuracy: 0.57\n",
      "Epoch: (04 / 05) | Time: 00:14 | Train Loss: 0.6518 | Val Loss: 0.6607 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:16 | Train Loss: 0.6329 | Val Loss: 0.6478 | Val Accuracy: 0.65\n",
      "Testing (69/81): (256, 128, 256, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:09 | Train Loss: 0.6915 | Val Loss: 0.6905 | Val Accuracy: 0.56\n",
      "Epoch: (02 / 05) | Time: 00:09 | Train Loss: 0.6844 | Val Loss: 0.6890 | Val Accuracy: 0.55\n",
      "Epoch: (03 / 05) | Time: 00:09 | Train Loss: 0.6730 | Val Loss: 0.6780 | Val Accuracy: 0.59\n",
      "Epoch: (04 / 05) | Time: 00:09 | Train Loss: 0.6573 | Val Loss: 0.6615 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:09 | Train Loss: 0.6397 | Val Loss: 0.6498 | Val Accuracy: 0.63\n",
      "Testing (70/81): (256, 128, 256, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:12 | Train Loss: 0.6912 | Val Loss: 0.6956 | Val Accuracy: 0.52\n",
      "Epoch: (02 / 05) | Time: 00:12 | Train Loss: 0.6833 | Val Loss: 0.6880 | Val Accuracy: 0.55\n",
      "Epoch: (03 / 05) | Time: 00:13 | Train Loss: 0.6697 | Val Loss: 0.6728 | Val Accuracy: 0.60\n",
      "Epoch: (04 / 05) | Time: 00:12 | Train Loss: 0.6506 | Val Loss: 0.6708 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:14 | Train Loss: 0.6348 | Val Loss: 0.6564 | Val Accuracy: 0.64\n",
      "Testing (71/81): (256, 128, 256, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:15 | Train Loss: 0.6886 | Val Loss: 0.6939 | Val Accuracy: 0.53\n",
      "Epoch: (02 / 05) | Time: 00:15 | Train Loss: 0.6783 | Val Loss: 0.6843 | Val Accuracy: 0.58\n",
      "Epoch: (03 / 05) | Time: 00:16 | Train Loss: 0.6617 | Val Loss: 0.6762 | Val Accuracy: 0.61\n",
      "Epoch: (04 / 05) | Time: 00:15 | Train Loss: 0.6434 | Val Loss: 0.6490 | Val Accuracy: 0.64\n",
      "Epoch: (05 / 05) | Time: 00:15 | Train Loss: 0.6311 | Val Loss: 0.6469 | Val Accuracy: 0.65\n",
      "Testing (72/81): (256, 256, 64, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:16 | Train Loss: 0.6897 | Val Loss: 0.6927 | Val Accuracy: 0.53\n",
      "Epoch: (02 / 05) | Time: 00:16 | Train Loss: 0.6815 | Val Loss: 0.6895 | Val Accuracy: 0.55\n",
      "Epoch: (03 / 05) | Time: 00:14 | Train Loss: 0.6688 | Val Loss: 0.6783 | Val Accuracy: 0.58\n",
      "Epoch: (04 / 05) | Time: 00:15 | Train Loss: 0.6522 | Val Loss: 0.6607 | Val Accuracy: 0.61\n",
      "Epoch: (05 / 05) | Time: 00:16 | Train Loss: 0.6363 | Val Loss: 0.6470 | Val Accuracy: 0.63\n",
      "Testing (73/81): (256, 256, 64, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:21 | Train Loss: 0.6907 | Val Loss: 0.6977 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:22 | Train Loss: 0.6793 | Val Loss: 0.6828 | Val Accuracy: 0.57\n",
      "Epoch: (03 / 05) | Time: 00:21 | Train Loss: 0.6645 | Val Loss: 0.6829 | Val Accuracy: 0.58\n",
      "Epoch: (04 / 05) | Time: 00:19 | Train Loss: 0.6456 | Val Loss: 0.6694 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:22 | Train Loss: 0.6312 | Val Loss: 0.6589 | Val Accuracy: 0.64\n",
      "Testing (74/81): (256, 256, 64, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:27 | Train Loss: 0.6885 | Val Loss: 0.6954 | Val Accuracy: 0.53\n",
      "Epoch: (02 / 05) | Time: 00:24 | Train Loss: 0.6744 | Val Loss: 0.6817 | Val Accuracy: 0.57\n",
      "Epoch: (03 / 05) | Time: 00:24 | Train Loss: 0.6564 | Val Loss: 0.6773 | Val Accuracy: 0.61\n",
      "Epoch: (04 / 05) | Time: 00:24 | Train Loss: 0.6408 | Val Loss: 0.6456 | Val Accuracy: 0.64\n",
      "Epoch: (05 / 05) | Time: 00:24 | Train Loss: 0.6311 | Val Loss: 0.6402 | Val Accuracy: 0.65\n",
      "Testing (75/81): (256, 256, 128, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:14 | Train Loss: 0.6907 | Val Loss: 0.6925 | Val Accuracy: 0.53\n",
      "Epoch: (02 / 05) | Time: 00:14 | Train Loss: 0.6833 | Val Loss: 0.6906 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:14 | Train Loss: 0.6682 | Val Loss: 0.6741 | Val Accuracy: 0.59\n",
      "Epoch: (04 / 05) | Time: 00:14 | Train Loss: 0.6492 | Val Loss: 0.6623 | Val Accuracy: 0.61\n",
      "Epoch: (05 / 05) | Time: 00:14 | Train Loss: 0.6326 | Val Loss: 0.6380 | Val Accuracy: 0.64\n",
      "Testing (76/81): (256, 256, 128, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:19 | Train Loss: 0.6900 | Val Loss: 0.6965 | Val Accuracy: 0.50\n",
      "Epoch: (02 / 05) | Time: 00:19 | Train Loss: 0.6778 | Val Loss: 0.6833 | Val Accuracy: 0.57\n",
      "Epoch: (03 / 05) | Time: 00:19 | Train Loss: 0.6594 | Val Loss: 0.6772 | Val Accuracy: 0.60\n",
      "Epoch: (04 / 05) | Time: 00:19 | Train Loss: 0.6397 | Val Loss: 0.6639 | Val Accuracy: 0.63\n",
      "Epoch: (05 / 05) | Time: 00:19 | Train Loss: 0.6269 | Val Loss: 0.6380 | Val Accuracy: 0.66\n",
      "Testing (77/81): (256, 256, 128, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:24 | Train Loss: 0.6891 | Val Loss: 0.6912 | Val Accuracy: 0.53\n",
      "Epoch: (02 / 05) | Time: 00:24 | Train Loss: 0.6766 | Val Loss: 0.6924 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:24 | Train Loss: 0.6578 | Val Loss: 0.6991 | Val Accuracy: 0.60\n",
      "Epoch: (04 / 05) | Time: 00:24 | Train Loss: 0.6399 | Val Loss: 0.6631 | Val Accuracy: 0.63\n",
      "Epoch: (05 / 05) | Time: 00:24 | Train Loss: 0.6292 | Val Loss: 0.6502 | Val Accuracy: 0.65\n",
      "Testing (78/81): (256, 256, 256, 3, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:14 | Train Loss: 0.6902 | Val Loss: 0.6921 | Val Accuracy: 0.53\n",
      "Epoch: (02 / 05) | Time: 00:14 | Train Loss: 0.6804 | Val Loss: 0.6894 | Val Accuracy: 0.54\n",
      "Epoch: (03 / 05) | Time: 00:14 | Train Loss: 0.6632 | Val Loss: 0.6745 | Val Accuracy: 0.60\n",
      "Epoch: (04 / 05) | Time: 00:14 | Train Loss: 0.6430 | Val Loss: 0.6631 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:14 | Train Loss: 0.6278 | Val Loss: 0.6459 | Val Accuracy: 0.65\n",
      "Testing (79/81): (256, 256, 256, 4, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:20 | Train Loss: 0.6886 | Val Loss: 0.6956 | Val Accuracy: 0.52\n",
      "Epoch: (02 / 05) | Time: 00:22 | Train Loss: 0.6767 | Val Loss: 0.6844 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:20 | Train Loss: 0.6601 | Val Loss: 0.6948 | Val Accuracy: 0.58\n",
      "Epoch: (04 / 05) | Time: 00:19 | Train Loss: 0.6409 | Val Loss: 0.6648 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 05) | Time: 00:21 | Train Loss: 0.6279 | Val Loss: 0.6523 | Val Accuracy: 0.64\n",
      "Testing (80/81): (256, 256, 256, 5, 0.4)\n",
      "Epoch: (01 / 05) | Time: 00:31 | Train Loss: 0.6889 | Val Loss: 0.6946 | Val Accuracy: 0.53\n",
      "Epoch: (02 / 05) | Time: 00:32 | Train Loss: 0.6753 | Val Loss: 0.6872 | Val Accuracy: 0.56\n",
      "Epoch: (03 / 05) | Time: 00:31 | Train Loss: 0.6557 | Val Loss: 0.6921 | Val Accuracy: 0.60\n",
      "Epoch: (04 / 05) | Time: 00:31 | Train Loss: 0.6363 | Val Loss: 0.6614 | Val Accuracy: 0.65\n",
      "Epoch: (05 / 05) | Time: 00:31 | Train Loss: 0.6239 | Val Loss: 0.6504 | Val Accuracy: 0.65\n",
      "Search complete. Best Hyperparameters: (256, 128, 64, 5, 0.4).\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "class_weights = class_weights.to(device)\n",
    "ind_dims_options = [64, 128, 256]\n",
    "comb_dims_options = [64, 128, 256]\n",
    "linear_dims_options = [64, 128, 256]\n",
    "num_layers_options = [3, 4, 5]\n",
    "dropout_options = [0.4]\n",
    "epochs = 5\n",
    "\n",
    "best_model = None\n",
    "best_hyperparams = None\n",
    "best_val_loss = 100 # arbitrary large number\n",
    "\n",
    "all_hyperparams = list(itertools.product(ind_dims_options, comb_dims_options, linear_dims_options, num_layers_options, dropout_options))\n",
    "\n",
    "for i, hyperparams in enumerate(all_hyperparams):\n",
    "    print(f\"Testing ({i}/{len(all_hyperparams)}): {hyperparams}\")\n",
    "    model = BiGRU(emb_dim, hyperparams[0], hyperparams[1], hyperparams[2], hyperparams[3], hyperparams[4])\n",
    "    model.to(device)\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "    scheduler = None\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "    val_loss = train_model(model, optimiser, scheduler, epochs, criterion, train_loader, val_loader, device)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_hyperparams = hyperparams\n",
    "        best_model = model\n",
    "        print(f\"Best Hyperparameters: [{hyperparams}] | Loss: {best_val_loss}\")\n",
    "\n",
    "print(f\"Search complete. Best Hyperparameters: {best_hyperparams}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the best model hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: (01 / 10) | Time: 00:18 | Train Loss: 0.6937 | Val Loss: 0.6851 | Val Accuracy: 0.59\n",
      "Epoch: (02 / 10) | Time: 00:17 | Train Loss: 0.6784 | Val Loss: 0.6920 | Val Accuracy: 0.60\n",
      "Epoch: (03 / 10) | Time: 00:17 | Train Loss: 0.6560 | Val Loss: 0.7034 | Val Accuracy: 0.61\n",
      "Epoch: (04 / 10) | Time: 00:18 | Train Loss: 0.6401 | Val Loss: 0.7001 | Val Accuracy: 0.62\n",
      "Epoch: (05 / 10) | Time: 00:18 | Train Loss: 0.6278 | Val Loss: 0.6751 | Val Accuracy: 0.66\n",
      "Epoch: (06 / 10) | Time: 00:18 | Train Loss: 0.6196 | Val Loss: 0.6665 | Val Accuracy: 0.67\n",
      "Epoch: (07 / 10) | Time: 00:18 | Train Loss: 0.6109 | Val Loss: 0.6639 | Val Accuracy: 0.66\n",
      "Epoch: (08 / 10) | Time: 00:18 | Train Loss: 0.6057 | Val Loss: 0.6582 | Val Accuracy: 0.67\n",
      "Epoch: (09 / 10) | Time: 00:18 | Train Loss: 0.5963 | Val Loss: 0.6459 | Val Accuracy: 0.67\n",
      "Epoch: (10 / 10) | Time: 00:18 | Train Loss: 0.5918 | Val Loss: 0.6324 | Val Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "class_weights = class_weights.to(device)\n",
    "best_hyperparams = [256, 128, 64, 5, 0.4] # As above\n",
    "epochs = 10\n",
    "model = BiGRU(emb_dim, individual_dim=best_hyperparams[0], combined_dim=best_hyperparams[1], linear_dim=best_hyperparams[2], num_layers=best_hyperparams[3], dropout=best_hyperparams[4])\n",
    "model.to(device)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "scheduler = None\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "val_loss = train_model(model, optimiser, scheduler, epochs, criterion, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Testing Model on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.81      0.77      1284\n",
      "         1.0       0.65      0.55      0.60       842\n",
      "\n",
      "    accuracy                           0.71      2126\n",
      "   macro avg       0.69      0.68      0.69      2126\n",
      "weighted avg       0.70      0.71      0.70      2126\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        premises = batch[0].to(device)\n",
    "        hypotheses = batch[1].to(device)\n",
    "        labels = batch[2].to(device).float()\n",
    "        outputs = model(premises, hypotheses)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_labels.extend(labels.cpu().numpy().flatten())\n",
    "        all_predictions.extend(preds.cpu().numpy().flatten())\n",
    "\n",
    "print(classification_report(all_labels, all_predictions))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"neutral\", \"entails\"])\n",
    "disp.plot(colorbar=False)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
